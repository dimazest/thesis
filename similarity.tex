\chapter{Background: distributional models of meaning}
\label{cha:background}

\section{The notion of similarity}
\label{sec:similarity}

Similarity is the degree of resemblance between two objects or events \cite{WCS:WCS1282} and plays a crucial role in psychological theories of knowledge and behaviour, where it is used to explain such phenomena as classification and conceptualisation \cite{Tversky1977,1986-13502-00119860101,medin1993respects,Markman1996,hahn1997concepts}. \textit{Fruit} is a \emph{category} because it is a practical generalisation. Fruits are sweet and generally constitute desserts, so when one is presented with an unseen fruit, one can hypothesise that it is served toward the end of a dinner.

Generalisations are extremely powerful in describing a language, as well. The verb \textit{runs} requires its subject to be singular. \textit{Verb}, \textit{subject} and \textit{singular} are categories that are used to describe English grammar. When one encounters an unknown word and is told that it is a verb, one will immediately have an idea about how to use it, assuming that it is used similarly to other English verbs.

From a computational perspective, this motivates and guides the development of \emph{semantic similarity} (in the sense that they measure the degree of resemblance of meaning) components that are embedded into natural language processing systems.

In Information Retrieval (IR), queries are expanded with related terms to increase the number of retrieved relevant documents. For example, if a user issues the query \textit{lakes in Sweden}, the system might add related words to the query such as \textit{lake}, \textit{reservoir}, \textit{river} or even \textit{swim} so that the documents that do not contain the word \textit{lakes} are retrieved \cite{Xu:1996:QEU:243199.243202}.
% \cite{Salton:1975:VSM:361219.361220}

A dependency parser might benefit from a generalisation about the part of speech tag of a word which did not occur in the training data, based on its occurrence pattern in a large corpus of documents from the web \cite{hermann-blunsom:2013:ACL2013,andreas-klein:2014:P14-2}.

The information that the word \textit{carpet} is similar in meaning to the word \textit{mat} might be exploited by a language model in estimating the probability of the sentence \textit{the cat set on the carpet}, even if it did not occur in the corpus, but \textit{cat sat on the mat} did \cite{bengio2006}.

A dialogue act tagging system might require classification of an utterance based on its role in a dialogue, such as a question or an acknowledgement \cite{kalchbrenner-blunsom:2013:CVSC}.

The examples show that similarity is a broad term that is goal-dependent. An IR system needs to identify semantically similar (\textit{lake}, \textit{river}) and related (\textit{lake}, \textit{swim}) terms. A dependency parser benefits from the similarity of word usage. A language model exploits similarity in word meaning. A dialogue act tagging system relies on the role similarity of the utterances. Also different linguistic entities are compared, the similarity can be measured between pairs of words and pairs of sentences.

\section{Representation for similarity measurement}
\label{sec:word-meaning}

According to \newcite{WCS:WCS1282}, ``similarity is an essentially psychological notion, based on the way we represent objects, that is, the way they appear to us.'' Since it is not yet known how objects are represented in human mind, the computational way of representing meaning to measure semantic similarity has to be agreed upon. However, one needs to be extremely careful when the meaning representation is decided, as it is unavoidably connected to the \emph{meaning of words in isolation}.

% The semantic formalisation of similarity is based on two ideas. The occurrence pattern of a word \emph{defines} its meaning \cite{firth1957lingtheory}, while the difference in occurrence between two words \emph{quantifies} the difference in their meaning \cite{harris1954distributional}.

Frege discusses two conflicting principles of meaning \cite{Janssen2001}. According to \emph{the principle of compositionality}, isolated word meanings are the building blocks of sentence meanings:
\begin{displayquote}[\cite{Janssen2001}]
The meaning of a compound expression is a function of the meaning of its parts and the syntactic rule by which they are combined.
\end{displayquote}
%
However, according to \emph{the principle of contextuality}, the word meaning in isolation is not defined:
\begin{displayquote}[\cite{Janssen2001}]
Never ask for the meaning of a word in isolation, but only in the context of a sentence.
\end{displayquote}

It is worth noting here that similarity in isolation is also problematic because the number of features an entity has is infinite, and it is easy to show that two entities will always have an infinite amount of common features \cite{goodman1972problems,hahn1997concepts}. For example, the tree next to my house is similar to my house because both of them are less than one kilometre in height, both of them are less than two kilometre in height, both of them are less than three kilometre in height and so on. 

To make similarity measurement possible, it has to be measured \emph{under a given description} \cite{WCS:WCS1282,medin1993respects,Markman1996}, thus, similarity is always contextualised. In other words, similarity emerges only when the possible properties are weighted. In our example, the tree and the house are similar with respect to the colour: both of them are green (the height properties are assigned zero weight).
% On the other side, \newcite{Huth2016} were able to comprehensively map individual words across cortex, meaning that there are word representations supporting the idea of \newcite{WCS:WCS1282}.

Frege's principle of contextuality allows us to define the meaning of a word by identifying its contribution to the meaning of a sentence. Firth's \citeyearpar{firth1957lingtheory} famous quote that ``you shall know a word by the company it keeps,'' suggests that the word meaning can be \emph{modelled} as the combination of the meanings of its occurrences in sentences of a corpus. Note that this does not provide the absolute word meaning, but only its meaning relative to the corpus. This assumption is also supported by the hypothesis of \newcite{harris1954distributional} that the differences of occurrences of two words quantify the \emph{difference} in their relative meaning, but do not necessarily \emph{define} the meaning.

Once the relative word meaning is accepted, compositionality can be used to obtain representations of phrases and sentences \cite{THEO:THEO373,Dowty1980,sep-montague-semantics,DBLP:journals/corr/abs-1003-4394,baroni2014frege}.

\section{Word meaning}
\label{sec:distr-hypoth}

% In principle, we would like to capture the intuition that while \textit{John} and \textit{Mary} are distinct entities, they are rather similar to each other (both of them are humans) and are dissimilar to \textit{dog}, \textit{pavement} or \textit{idea}. However, we start with the word meaning representation that captures the fact that entities are distinct, but does not provide the means to measure similarity.

% The same applies at the phrase and sentence level: \textit{dogs chase cats} is similar in meaning to \textit{hounds pursue kittens}, but less so to \textit{cats chase dogs} (despite the lexical overlap).

\subsection{Formal semantics}
\label{sec:classical-approaches}

Formal semantics provides the means to infer some piece of information from another. The main studied relation is the entailment of sentences, for example, \textit{John swims in Åresjön} entails \textit{John swims in a Swedish lake}. To evaluate entailment, the sentences are converted to formulas. The words correspond to symbols in formal logic.

The individual \textit{Åresjön} corresponds to the symbol \textit{Åresjön'}, which is mapped to the actual lake by the interpretation function $\mathcal{I}$.

One-place properties are seen as sets of individuals, so $\mathcal{I}(\mathit{Swedish'})$ is a set that contains $\mathcal{I}(\mathit{Åresjön'})$ and $\mathcal{I}(\mathit{Väsman'})$ among many other entities.

\textit{Swim'} is a two-place predicate that is represented as a set that contains the pairs between which the relation holds, so if John actually swims in Åresjön, then $\mathcal{I}(\mathit{swim'})$ will contain the pair $(\mathcal{I}(\mathit{John'}), \mathcal{I}(\mathit{Åresjön'}))$.

While such formalism is very powerful for entailment detection between sentences, similarity measurement is problematic, because there is no relation between atomic symbols: we only know that \textit{Åresjön} and \textit{Väsman} correspond to different entities in the universe, but know nothing about their properties.

\subsection{Distributional semantics}
\label{sec:distr-repr}

Distributional methods provide a way to measure similarity between symbols. The representations are produced by directly exploiting Harris' \citeyearpar{harris1954distributional} intuition that similar words occur in similar contexts.

For example, one can construct a vector space in which the dimensions correspond to contexts, which are usually other words. The word vector components can then be calculated by taking the frequency with which the word co-occurred with the corresponding contexts within a predefined window in a corpus of interest. The similarity in meaning can be expressed via a suitable distance metric within the space.

\begin{wraptable}[9]{O}{7cm}
  \centering
  \vspace{-1em}
  \begin{tabular}{lrrr}
    \toprule
    & philosophy & book & school \\
    \midrule
    John & 4  & 60 & 59  \\
    Mary & 0  & 10 & 22  \\
    girl & 0  & 19 & 93  \\
    boy  & 0  & 12 & 146 \\
    idea & 10 & 47 & 39  \\
    \bottomrule
  \end{tabular}
  \caption{Word co-occurrence frequencies extracted from the BNC}
  \label{tab:comparison}
\end{wraptable}

Table~\ref{tab:comparison} shows five three-dimensional vectors for words \textit{Mary}, \textit{John}, \textit{girl}, \textit{boy} and \textit{idea}. The words \textit{philosophy}, \textit{book} and \textit{school} label vector space dimensions.

As the vector for \textit{Mary} is closer to \textit{girl} than it is to \textit{boy} in the vector space, we can say that \textit{Mary}'s contexts are similar to \textit{girl}'s (and less similar to \textit{boy}'s), therefore \textit{Mary} is semantically more similar to \textit{girl} than to \textit{boy}.

Mathematically, the similarity can be expressed using, for instance, the cosine of the angle between two vectors:
%
\begin{align*}
\cos(\theta) &=
\frac{\ov{\mathit{Mary}}\cdot\ov{\mathit{girl}}}
{||\ov{\mathit{Mary}}||||\ov{\mathit{girl}}||} =
%
\frac{(0\times0) + (10\times19) + (22\times93)}
% * <sdyck@ualberta.ca> 2016-11-03T02:13:08.483Z:
%
% > {(0\times0) + (10\times19) + (22\times93)
%
% adding parentheses makes it easier to tell where the numbers came from, but feel free to remove them if you want/disagree. 
%
% ^.
{\sqrt{0^2 + 10^2 + 22^2}\sqrt{0^2 + 19^2 + 93^2}} \approx
\frac{2236}{2294} \approx 0.975
 \\
\cos(\phi) &=
\frac{\ov{\mathit{Mary}}\cdot\ov{\mathit{boy}}}
{||\ov{\mathit{Mary}}||||\ov{\mathit{boy}}||} =
%
\frac{(0\times0) + (10\times12) + (22\times146)}
{\sqrt{0^2 + 10^2 + 22^2}\sqrt{0^2 + 12^2 + 146^2}} \approx
\frac{3332}{3540} \approx 0.941
\end{align*}
%
where $\theta$ is the angle between the vectors of \textit{Mary} and \textit{girl}; and $\phi$ is the angle between the vectors of \textit{Mary} and \textit{boy}.

In the current example of a na{\"\i}ve vector space, \textit{John} is also closer to \textit{girl} than to \textit{boy}, which is counter-intuitive. This might be because of the small number of dimensions used, the poor selection of the context words, or the usage of raw co-occurrence numbers. Refer to \newcite{Turney:2010:FMV:1861751.1861756} and \newcite{TACL570} for the discussion of vector space parameters, and see \newcite{kiela-clark:2014:CVSC}, \newcite{lapesa2014large} and Chapter~\ref{sec:parameters} for the detailed descriptions of vector space parameters.

\subsection{Neural word embeddings}
\label{sec:neural-embedding}

Deep learning techniques use the distributional hypothesis differently. Instead of relying on observed co-occurrence frequencies, a neural model is trained to maximise some objective function related to, for example, the probability of observing the surrounding words in some context \cite{mikolov2013distributed}:
% * <sdyck@ualberta.ca> 2016-11-03T02:27:02.618Z:
%
% > differently
%
% differently than what? co-occurrence​ based vectors?
%
% ^.
%
\begin{align}
 \frac{1}{T}\sum^{T}_{t=1}\sum_{-c \leq j \leq c, j\neq0} \log p(w_{t+j}|w_t)
  \label{eq:objective-func}
\end{align}
%
\noindent
Maximising this function produces vectors which maximise the
conditional probability of observing words in a context around the
target word $w_t$, where $c$ is the size of the training context, and
$w_1 w_2, \cdots w_T$ is a sequence of training words. Therefore, they
capture the distributional intuition and can express degrees of
lexical similarity.

They have also been proved to be successful at other tasks \cite{mikolov2013linguistic}. The vectors obtained by this method encode not only attributional similarity (similar words are close to each other), but also relational similarities \cite{Turney:2010:FMV:1861751.1861756}. For example, it is possible to extract the \texttt{singular:plural} relation (\textit{apple}:\textit{apples}, \textit{car}:\textit{cars}) using vector subtraction:
%
\begin{align*}
  \overrightarrow{\mathit{apple}} - \overrightarrow{\mathit{apples}}
  \approx
  \overrightarrow{\mathit{car}} - \overrightarrow{\mathit{cars}}
\end{align*}
%
also, semantic relationships are preserved:
%
\begin{align*}
  \overrightarrow{\mathit{king}} - \overrightarrow{\mathit{man}}
  \approx
  \overrightarrow{\mathit{queen}} - \overrightarrow{\mathit{woman}}
\end{align*}
%
allowing the formation of analogy queries similar to
$\overrightarrow{\mathit{king}} - \overrightarrow{\mathit{man}} +
\overrightarrow{\mathit{woman}} = \mathtt{?}$, obtaining
$\overrightarrow{\mathit{queen}}$ as the
result.

\newcite{levy2014linguistic} refined the method of retrieving relational similarities by changing the objective function and improved the state-of-the-art results, both for neural embeddings and co-occurrence based vectors. However, recently the evaluation method based on analogies and vector offsets has been criticised---see \newcite{linzen:2016:RepEval}.

\section{Similarity of phrases and sentences}
\label{sec:similarity-compounds}

Both neural and co-occurrence-based approaches have advantages over the formal approaches in their ability to capture lexical semantics and degrees of similarity. However, their success at extending this to the sentence level, and to more complex semantic phenomena, depends on their applicability within compositional models.

\subsection{The principle of compositionality}
\label{sec:formal-semantics}

Formal approaches to the semantics of natural language have built upon the
classical idea of compositionality which states that the meaning of a sentence is a
function of its parts \cite{Janssen2001}. In compositional type-logical
approaches, predicate-argument structures representing phrases and sentences are
built from their constituent parts by general operations such as beta-reduction
within the lambda calculus \cite{THEO:THEO373}: for example, given a semantic
representation of \emph{John} as $\mathit{john}'$ and \emph{loves} as
$\lambda y.\lambda x.\mathit{loves}'(x, y)$, the sentence \emph{John loves Mary}
can be constructed as
$$
\lambda y.\lambda
x.\mathit{loves}'(x, y)(\mathit{mary}')(\mathit{john}') =
\mathit{loves}'(\mathit{john}', \mathit{mary}')
$$

To get the semantic representation of the sentence \textit{John loves Mary}, we
need to do the following. Syntactic rules define how constituents are combined
% * <sdyck@ualberta.ca> 2016-11-03T03:32:46.899Z:
%
% > need to do the following
%
% What needs to be done? This doesn't fit with how the rest of the paragraph is phrased.
%
% ^.
to form other constituents (and finally a sentence). Translation rules define
how semantic representations of the constituents are combined to get a semantic
representation of the whole.

Categorical grammars are widely used to obtain the syntactic structure of a sentence. Given a set of basic categories $\texttt{ATOM}$, for example $\{\mathit{n}, \mathit{s}, \mathit{np}\}$ complex categories
% * <sdyck@ualberta.ca> 2016-11-05T01:33:12.755Z:
%
% > xample $\{\mathit{n}, \mathit{s}, \mathit{np}\}$ complex categories
%
% what do these categories mean?
%
% ^.
$\mathtt{CAT} \backslash \mathtt{CAT}$ and $\mathtt{CAT}/\mathtt{CAT}$ can be constructed, where $\mathtt{CAT}$ is either an element of \texttt{\texttt{ATOM}} or a complex category. So the transitive verb category is $\mathtt{np}\backslash\mathtt{s}/\mathtt{np}$. Intuitively, we want to say that to obtain a sentence with a transitive verb there must be noun phrases before and after the verb.

Parsing is done by composing categories together according to two rules:
%
\begin{enumerate}
\item \textbf{Backward application}: If $\alpha$ is a string of category $A$ and
  $\beta$ is a string of category $A\backslash{}B$, then $\alpha\beta$ is of
  category $B$.
\item \textbf{Forward application}: If $\alpha$ is a string of category $A$ and
  $\beta$ is a string of category $B/A$, then $\beta\alpha$ is of category $B$.
\end{enumerate}

\begin{figure}
  \centering
  \Tree [
    .$s$
    [
      .$\mathit{np}$
      John
    ]
    [
      .$\mathit{np}\backslash{}s$
      [
        .$\mathit{np}\backslash{}\mathit{s}/\mathit{np}$
        loves
      ]
      [
        .$\mathit{np}$
        Mary
      ]
    ]
  ]
  \caption[A syntactic tree]{A syntactic tree for \textit{John loves Mary}. The lexicon assigns
    categories to words: \textit{John} is $\mathit{np}$, loves is
    $\mathit{np}\backslash{}\mathit{s}/\mathit{np}$ and Mary is
    $\mathit{np}$. Backward and forward composition rules derive the syntactic
    tree.}
\label{fig:cg}
\end{figure}

Figure~\ref{fig:cg} illustrates the parse tree for \textit{John loves Mary}
obtained using the category composition rules.

The last step is to map syntactic categories with semantic terms. Again, there
are base types ($e$ for entities and $t$ for sentences) and complex types of the
form $(a \to b)$ where $a$ and $b$ are types. The mapping between syntactic
categories and semantic types is defined as a function $\mathit{type}$:
%
\begin{align*}
  &\mathit{type}(np) = e \\
  &\mathit{type}(s) = t \\
  &\mathit{type}(A/B) = (\mathit{type}(B) \to \mathit{type}(A)) \\
  &\mathit{type}(B\backslash{}A) = (\mathit{type}(B) \to \mathit{type}(A)) \\
\end{align*}

Syntactic backward and forward application corresponds to functional
application. Figure~\ref{fig:syn} shows the final parse tree.

\begin{figure}
  \centering
  \Tree [
    .$s$~:~$\mathit{loves}'(\mathit{john}',\mathit{mary}')$
    [
      .$\mathit{np}$~:~$\mathit{john}'$
      John
    ]
    [
      .$\mathit{np}\backslash{}s$~:~$\lambda~x.\mathit{loves}'(x,~\mathit{mary}')$
      [
        .$\mathit{np}\backslash{}\mathit{s}/\mathit{np}$~:~$\lambda{}y.\lambda{}x.\mathit{loves}'(x,y)$
        loves
      ]
      [
        .$\mathit{np}$~:~$\mathit{mary}'$
        Mary
      ]
    ]
  ]
  \caption{The final parse tree}
\label{fig:syn}
\end{figure}

Given a suitable pairing between a syntactic grammar, semantic representations and corresponding general combinatory operators, this can produce structured sentential representations with a broad coverage and good generalisability \cite{step2008:2222}. This logical approach is extremely powerful because it can capture complex aspects of meaning such as quantifiers and their interactions \cite{Copestake2005}, and enables inference using well studied and developed logical methods \cite{bos2000first}.

\subsection{Compositional distributional semantics}
\label{sec:composition}

Methods based on the distributional hypothesis have recently been applied to many tasks, but mostly at the word level, for instance, word sense disambiguation \cite{ZhitomirskyGeffet2009} and lexical substitution \cite{Thater:2010:CSR:1858681.1858778}. They exploit the notion of similarity which correlates with the angle between word vectors \cite{Turney:2010:FMV:1861751.1861756}.

\emph{Compositional} distributional semantics goes beyond the word level and models the meaning of phrases or sentences based on their parts. \newcite{mitchell-lapata:2008:ACLMain} perform composition of word vectors using vector addition and multiplication operations. The limitation of this approach is the operator associativity, which ignores the argument order, and thus word order. As a result, ``\textit{John loves Mary}'' and ``\textit{Mary loves John}'' get assigned the same meaning.

Concretely, if \textit{John}'s, \textit{Mary}'s and \textit{loves}'s meanings are
represented as vectors $\ov{\mathit{john}}$, $\ov{\mathit{mary}}$ and
$\ov{\mathit{loves}}$, the meaning of the sentence \textit{John loves Mary} is
$\ov{\mathit{john}} + \ov{\mathit{loves}} + \ov{\mathit{mary}}$.

To capture word order and the syntactic structure of a sentence, various approaches have been proposed. \newcite{Grefenstette:2011:ESC:2145432.2145580} extend the compositional approach by using non-associative linear algebra operators as proposed in the theoretical work of \newcite{DBLP:journals/corr/abs-1003-4394}.

The functional applications of semantic terms can be replaced with tensors \cite{Bourbaki1998commutative}. Then, a transitive verb is represented by a matrix, which can be obtained from a corpus using the formula $\sum_i\ov{s_i} \otimes \ov{o_i}$ \cite{Grefenstette:2011:ESC:2145432.2145580}, where $\ov{s_i}$ and $\ov{i_i}$ are the subject-object pairs of the verb and $\otimes$ is the Kronecker product. The vector of the whole sentence is $\overline{\mathit{loves}} \odot(\ov{\mathit{john}} \otimes \ov{\mathit{mary}})$, where $\odot$ is the element-wise product.
% * <sdyck@ualberta.ca> 2016-11-03T03:46:50.769Z:
%
% > it{loves
%
% Should this have a vector symbol above it, rather than a straight line?
% DM: no, becausue it's a matrix, not a vector.
% ^.

\subsection{Similarity of heads in context}
\label{sec:similarity-context}

A noun phrase can be similar to a noun, as in \textit{female lion} and \textit{lioness}, and to other noun phrases as in \textit{yellow car} and \textit{cheap taxi}. The same similarity principle can be applied to phrases as well as to words. In this case, similarity is measured in \emph{context}, and most methods of calculating similarity of phrases still rely on comparisons of the phrases' head words, which meanings are modified by the arguments they appear with \cite{Kintsch2001173}.

\newcite{mitchell-lapata:2008:ACLMain,mitchell2010composition} use element-wise addition and multiplication to model argument interaction. \newcite{Baroni2010nouns} represents adjectives as matrices that modify nouns (vectors) using matrix multiplication.

\newcite{Dinu:2010:MDS:1870658.1870771} model word meaning as a distribution over senses; a context feature (other word in the context)  directly modulates word’s sense distribution using conditional probability. \newcite{thater-furstenau-pinkal:2011:IJCNLP-2011} contextualise vectors by assigning higher weight to features that correspond or are distributionally similar to the context words.

% \cite{Seaghdha:2011:PMS:2145432.2145545}.

With verbs, similarity in context can be applied to compare a transitive and intransitive verb. For example, \textit{cycle} is similar to \textit{ride a bicycle}. Here we see that \textit{a bicycle} disambiguates the verb \textit{ride} making the phrase similar to the verb \textit{cycle}. The connection between measuring similarity of a phrase and disambiguation has been noted in \newcite{kartsaklis-sadrzadeh-pulman:2013:CoNLL-2013}.

% TODO: mention \cite{wieting2015paraphrase}

Sentential similarity might be treated as the similarity of the heads in their contexts. That is, the similarity between \textit{sees} and \textit{notices} in \textit{John \textbf{sees} Mary} and \textit{John \textbf{notices} a woman}. This approach abstracts away the grammatical difference between the sentences and concentrates on their semantics.

\section{Evaluation}
\label{sec:intrinsic-evaluation}

The difference in occurrence between two words quantifies the difference in their meaning \cite{harris1954distributional} and there is a machinery to measure the difference in the meanings of two sentences \cite{DBLP:journals/corr/abs-1003-4394}. The final necessary part is the evaluation methodology to test this approach.

Because it is difficult to perform extrinsic evaluation (also called evaluation in use) to measure the performance of a similarity component in a pipeline of a complete natural language processing system (for example, a dialog system), intrinsic datasets that focus on similarity are popular among computational linguists.

Apart from a pragmatic attempt to alleviate the problems of evaluating
similarity components, these datasets serve as an empirical test of the
hypotheses of Firth and Harris, bringing together our understanding of the human mind, language and technology. The following sections introduce the main datasets used in this area.

\subsection{Word similarity}
\label{sec:lexical-similarity}

Two datasets, namely MEN \cite{Bruni:2012:DST:2390524.2390544} and SimLex-999 \cite{hill2014simlex}, are currently widely used. They are designed especially for meaning representation evaluation and surpass datasets stemming from psychology \cite{1986-13502-00119860101}, information retrieval \cite{2002:PSC:503104.503110} and computational linguistics \cite{Rubenstein:1965:CCS:365628.365657} in quantity by having more entries and, in the case of SimLex-999, attention to the evaluated relation by distinguishing similarity from relatedness. The datasets provide similarity (relatedness) scores between word pairs.
% * <sdyck@ualberta.ca> 2016-11-03T03:57:45.676Z:
%
% > The datasets provide similarity (relatedness) scores between word pairs.
%
% You just stated that one dataset distinguishes similarity from relatedness, so it's a bit contradictory to say here that they are the same thing. Possibly rephrase. 
%
% ^.

\subsection{Disambiguation of verbs in context}
\label{sec:disamb}

The transitive verb disambiguation dataset
% \footnote{This and the sentence  similarity datasets are available at \url{http://www.cs.ox.ac.uk/activities/compdistmeaning/}}
described in \newcite{Grefenstette:2011:ETV:2140490.2140497} consists of ambiguous transitive verbs together with their arguments, landmark verbs (which identify one of the verb senses) and human judgements (which specify the similarity to the landmarks of the disambiguated sense of the verb in the given context). This is similar to the intransitive dataset described in \newcite{mitchell-lapata:2008:ACLMain}.

Consider the sentence \textit{system meets specification}. \textit{Meets} is an ambiguous transitive verb, and \textit{system}
and \textit{specification} are its arguments. Possible landmarks for \emph{meet} are \textit{satisfy} and \textit{visit}. For this sentence, the human judgements show that the disambiguated verb meaning is similar to the landmark \textit{satisfy}, and less similar to \textit{visit}.

The task is to estimate the similarity of the sense of a verb in a context with a given landmark. To estimate similarity, the verb is composed with its arguments, it is done the same for the landmark and the arguments, and the similarity of the two vectors is computed. To evaluate performance, the human judgements are averaged for the same verb, argument and landmark entries, and these average values are used to calculate the correlation.

\subsection{Sentence similarity}
\label{sec:sentence-similarity}

The transitive sentence similarity dataset described in \newcite{kartsaklis-sadrzadeh-pulman:2013:CoNLL-2013} consists of transitive sentence pairs and human similarity judgements. The task is to estimate similarity between two sentences. The evaluation is the same as in Section~\ref{sec:disamb}.

\subsection{Relevance}
\label{sec:relevance}

\newcite{Milajevs:2015:IMN:2808194.2809448} investigated whether distributional
models of meaning and similarity are applicable to Information Retrieval (IR). Despite the strong assumption that relevant documents are similar, they show that compositional models are essential for semantic IR tasks.

Chapter~\ref{sec:phraserel} introduces a new dataset that provides relevance judgements of subject-verb-object phrases and aims for an evaluation that is closer to the widely used evaluation metrics in IR. Namely, we calculate the percentage of the queries for which there is a relevant document among the top three ranked.

\section{Conclusion}
\label{sec:conclusion-comp}



%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis.tex"
%%% TeX-engine: xetex
%%% End:
