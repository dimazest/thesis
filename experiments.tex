% \chapter{Intrinsic experiments}
% \label{cha:experiments}

% Table~\ref{tab:parameters} lists parameters and their values. As the source corpus we use the concatenation of Wackypedia and ukWaC \cite{ukwac} with a symmetric 5-word window \cite{milajevs-EtAl:2014:EMNLP2014}; the evaluation metric is the correlation with human judgements as is standard with SimLex \cite{hill2014simlex} and other lexical datasets.

\todo[inline]{
  What's the best selection method.
  Does Max overfit?  Statistical significance.
  Title: mention PMI?
  Lexical comparison with other work.
}

% We derive our parameter selection heuristics by greedily selecting parameters (\texttt{cds}, \texttt{neg}) that lead to the highest average performance for each combination of frequency weighting, PMI variant and dimensionality $D$. Figures~\ref{fig:interaction-cds} and \ref{fig:interaction-neg} show the interaction of \texttt{cds} and \texttt{neg} with other parameters. We also vary the similarity measure (cosine and correlation  \cite{kiela-clark:2014:CVSC}), but do not report results here due to space limits.

\chapter{Similarity and relatedness of words}
\label{sec:lexical}

\section{SimLex-999}
\label{sec:simlex-999}

\subsection{Max selection}
\label{sec:max-selection-simlex}

\input{figures/SimLex999-results}

Figure~\ref{fig:SimLex999-results} illustrates the results based on the best model selection and Table~\ref{tab:parameters} shows the results together with picked parameters. Note that the maximum selection is identical with cross-validation: they pick the same models.

In general, model performance increases as the dimensionality increases. However, the best result of 0.389 is achieved with a 2000 dimensional space, this could, however, be an example of overfitting. Model performance becomes stable for dimensions greater than 20000.

For spaces with dimensionality less than 5000 \texttt{freq} 1 and inner product yield best results. Otherwise, cosine with \logNSCPMI/, smoothing $\alpha=0.75$ and shifting $k=0.7$ gives the best results.

\input{figures/SimLex999-max-selection-table.tex}

\subsection{Heuristics}
\label{sec:heuristics-simlex}

\input{figures/SimLex999-ablation.tex}

% \input{figures/SimLex999-interaction.tex}

The linear model achieves an adjusted $R^2$ of 0.867, indicating that the model is able to predict model performance based on parameter selection quite well. Table~\ref{tab:SimLex999-ablation} shows partial $R^2$ scores for parameters. The most influential parameters in decreasing order are similarity, \texttt{freq} and \texttt{neg}.

\input{figures/SimLex999-similarity}
Figure~\ref{fig:SimLex999-similarity} shows the average performance of similarity measures. Correlation outperforms all other measures for all dimensions and peaks at the dimensionality of 20000 after correlation is chosen as the similarity measure.

% \input{figures/SimLex999-freq}
The influence of \texttt{freq}, the second parameter, is shown on Figure~\ref{fig:SimLex999-freq}. $\log n$ frequency outperforms other choices for all dimensions. After 20000 dimensions $\log n$'s performance stabilises: variance decreases and the performance stays constant.

\input{figures/SimLex999-neg}
The third parameter \texttt{neg} of 0.7 shows the best performance (Figure~\ref{fig:SimLex999-neg}). However, there is little difference between models with dimensionality greater than 20000, apart from the models that do not perform shifting, whose performance peaks at 20000 dimensions and decreases afterwards with increasing variance.

% \input{figures/SimLex999-discr}
There is little difference between SPMI and SCPMI performance with a little advantage to SCPMI (Figure~\ref{fig:SimLex999-discr}).

\input{figures/SimLex999-cds}
Finally, models benefit from context distribution smoothing, spaces with less than 10000 dimensions produce the best results with $\alpha = 1$, for spaces with higher dimensionality $\alpha = 0.75$ is the most advantageous (Figure~\ref{fig:SimLex999-cds}).

\todo[noline]{Contrast or compare results with \cite{milajevs-sadrzadeh-purver:2016:ACL-SRW}}

\subsection{Difference between Max selection and heuristics on SimLex-999}

\input{figures/SimLex999-heuristics-selection-table}

As expected manual parameter selection is more stable as Table~\ref{tab:Simlex999-heuristics-selection} shows. Both selection models agree on parameters for highly dimensional spaces ($D \geq 2000$), with an exception of similarity: Max selection prefers cosine, while manual prefers correlation based similarity measure. Because of this, manual selection does not pick the best result of the 2000 dimensional model, but at 50000 dimensions  a model selected manually scores 0.001 lower: 0.384 versus 0.385 as also seen on Figure~\ref{fig:SimLex999-results}.

The average relative difference between Max selection and heuristics is 0.039.

\section{MEN}
\label{sec:men}

\subsection{Max selection}
\label{sec:max-selection-men}

\input{figures/men-results}

Figure~\ref{fig:men-results} shows the selection results. Again, cross-validation results are identical with Max selection. Table~\ref{tab:men-max-selection} shows the results together with the selected models.

\input{figures/men-max-selection-table}

Model performance monotonically increases as the dimensionality increases. The highest score of 0.765 is achieved by 3 spaces with $D \geq 30000$, \logNSCPMI/, smoothed context distribution ($\alpha = 0.75$), shifted PMI values ($k = 1$) and the similarity measure based on correlation.

In comparison with SimLex-999, models with ``more extreme'' parameters give better results. For example, $\alpha = 0.75$ is the best for models tested on SimLex-999 with dimensionality starting with 20000, while for models tested on MEN, this parameter choice is the best starting with 5000. Similar behaviour is observed for \texttt{neg} and similarity. For highly dimensional spaces the switch from SimLex-999 to MEN changes the best \texttt{neg} choice from 0.7 to 1 and similarity from cosine to correlation. Such a switch of parameter choices might suggest the difference between \textit{relatedness} and \textit{similarity}.

\subsection{Heuristics}
\label{sec:heuristics-men}

\input{figures/men-ablation}
The linear model gives an adjusted $R^2$ of 0.733, which is lover than on SimLex-999, but is still high. Table~\ref{tab:men-ablation} shows partial $R^2$ scores for the explored parameters. The most influential parameter is \texttt{neg}, followed by \texttt{freq} and similarity. This is different in case of SimLex-999 where these parameters influence ``order'' is reversed.

\input{figures/men-neg}
\texttt{neg} with $k = 2$ is preferable for spaces with dimensionality less than 20000, for spaces with more dimensions,
\todo{compare with Levy, they also suggest $k=5$.}
$k = 5$ is more beneficial (Figure~\ref{fig:men-neg}).  We, however, expect that for spaces with more than 500000 dimensions even higher values should be preferred. This contrasts with the heuristics derived from SimLex-999, where single \texttt{neg} value of 0.7 is chosen.

% \input{figures/men-freq}
Regarding the frequency component, $\log n$ outperforms all other choices (Figure~\ref{fig:men-freq}). It is exactly same choice as for heuristics based on SimLex-999.

\input{figures/men-similarity}
Correlation is the preferred similarity measure (Figure~\ref{fig:men-similarity}), again this is inline with the choice based on SimLex-999.

% \input{figures/men-discr}
SPMI is the preferred discriminativeness (Figure~\ref{fig:men-discr}), however it is closely followed by CPMI and SCPMI. This contrasts with SimLex-999, where SCPMI is preferred, however in both cases the difference between the two discriminativeness choices is minimal.

\input{figures/men-cds}
Global context probability gives on average higher results for MEN (Figure~\ref{fig:men-cds}), while SimLex-999 prefers context distribution smoothing (Figure~\ref{fig:SimLex999-cds}).

\subsection{Difference between Max selection and heuristics on MEN}

\input{figures/men-heuristics-selection-table}

The two selection procedures agree on fewer parameters than the ones bases on SimLex-999. Both agree on discrimination ($\log n$) and similarity score for spaces with dimensionality greater than 10000 (correlation). While SCPMI is chosen by Max selection, SPMI is preferred by the selection based on heuristics, however the difference between the two is minimal. In contrast to the Max selection, which chooses the models with context distribution smoothing, heuristics prefer models with global context probabilities. Also, heuristics pick models with higher shifting values $\alpha$ (2 and 5), in contrast to Max selection, where 0.7 and 1 are picked. Table~\ref{tab:men-heuristics-selection} summarises the parameter selection based on heuristics.

The average difference between Max selection and heuristics is 0.008.

\section{Selected model transfer to another dataset}
\label{sec:select-model-transf}

\subsection{Difference between heuristics based on MEN and SimLex-999}

Heuristics based on MEN agree with ones bases on SimLex-999 on two parameters: frequency ($\log n$) and similarity (correlation). The methods disagree on \texttt{discr} (SCPMI versus SPMI, but again the difference is neglectable), context distribution (smoothed versus global) and shifting parameter, for which higher values for MEN are preferred.

\subsection{From SimLex-999 to MEN}

\input{figures/lexical-transfer}

The models selected using heuristics based on the SimLex-999 dataset perform well on MEN: for all dimensions the selected models are close to the best possible score (Figure~\ref{fig:SimLex999-transfer}). The average difference with the upper bound is 0.006.

The max based selection comes close to the upper bound for models with dimensionality greater than 5000. The average difference with the upper bound is 0.039.

In this case, heuristic based selection leads to better performance than the Max based selection.

\subsection{From MEN to SimLex-999}

Heuristics transferred from MEN to SimLex-999 behave less efficient, they do not always outperform Max selection, though for highly dimensional spaces the difference decreases (Figure~\ref{fig:men-transfer}). The average difference is 0.062, which is ten times more than the transition from SimLex-999 to MEN.

Max selection neither picks the best possible results when transferred from MEN to SimLex-999, however the average difference is lower: it is 0.042. This is similar to the transition in other direction.

Max based selection leads to better performance than the heuristics for MEN.

\section{Universal parameter selection for lexical datasets}
\label{sec:universal-lexical-param-selection}

\input{figures/lexical-results}

Figure~\ref{fig:lexical-results} shows performance of the models based on the average of the normalised scores over SimLex-999 and MEN. The performance of selected models on both datasets and the normalised average is shown on Table~\ref{tab:lexical-max-selection} (Max selection) and Table~\ref{tab:lexical-heuristics-selection} (selection based on heuristics).
%
\todo[noline]{Compare with Baroni and Levy.}

\subsection{Max selection}
\label{sec:max-selection}

In general, the more dimensions, the better the results are. The selection yields the best results at $D = 50000$ for SimLex-999 and at $D = 3000$ for MEN. While for SimLex-999,  the Max selection approaches the upper limit after 20000 dimensions; for MEN, it peaks and slightly deviates from the upper bound as the dimensionality increases.

The Max parameter selection based on the combination of the two lexical datasets is closer to the Max selection based on SimLex-999 (Table~\ref{tab:Simlex999-max-selection}) than on MEN (Table~\ref{tab:men-max-selection}).

\input{figures/lexical-max-selection-table}

\subsection{Heuristics}

\input{figures/lexical-ablation}

The linear model achieves an adjusted $R^2$ of 0.817, which is less then $R^2 = 0.867$ of SimLex-999, but is greater than the $R^2 = 0.733$ of MEN. Table~\ref{tab:lexical-ablation} shows partial $R^2$ for each parameter, the most influential are similarity, \texttt{neg} and \texttt{freq}.

\input{figures/lexical-similarity}
Correlation is the similarity measure of choice (Figure~\ref{fig:lexical-similarity}).

% \input{figures/lexical-neg}
For the models with dimensionality less than 20000 shifting should be used with $k = 1$, otherwise $k = 2$ is preferred (Figure~\ref{fig:lexical-neg}).

\input{figures/lexical-freq}
$\log n$ on average performs the best as the frequency component (Figure~\ref{fig:lexical-freq}).

% \input{figures/lexical-discr}
SCPMI is the preferred discrimination component, but SCPMI is very close to it (Figure~\ref{fig:lexical-discr}).

\input{figures/lexical-cds}
Global context probabilities on average behave the best (Figure~\ref{fig:lexical-cds}).

\input{figures/lexical-heuristics-selection-table}

\subsection{Comparison with single dataset based selections}

Both selection methods mostly agree on frequency ($\log n$) and discriminativeness (SCPMI).

Context probability distribution smoothing varies between the selection methods, but follows the corresponding procedures based on MEN.

The Max based selection for \texttt{neg} follows the Max selection on SimLex-999.

Even though the similarity choice is different between the Max and heuristic selections, it is consistent with SimLex-999 in both cases and with MEN for the heuristic-based selection.

For the Max-based selection, the average difference is 0.020 on SimLex-999 and 0.004 for MEN.

For the heuristics-based selection, the average difference is 0.048 for SimLex-999 and 0.010 for MEN.

Max selection behaves better than the heuristics based on the average difference, but we can not check how well these two selections behave on other lexical datasets.

Based on the experiments, \logNSCPMI/ with shifting close to 1 is the quantification of choice for the lexical tasks, however more work needs to be done to find robust choice for context distribution smoothing and similarity measure choice.

\chapter{Similarity of sentences}
\label{sec:sentential}

\todo[inline]{Selection description: global best; best operator, its general behaviour, general behaviour of others; parameters.}

\section{KS14}
\label{sec:ks14}

\subsection{Max selection}
\label{sec:max-selection-ks14}

\input{figures/ks14-results}

Figure~\ref{fig:ks14-results} shows the performance of compositional model on the sentence similarity dataset KS14 \cite{kartsadrqpl2014}.
All operators outperform the non-compositional \texttt{head} operator. Table~\ref{tab:ks14-max-selection} shows the performance of models selected by Max selection together with the selected parameters.

\todo[noline]{Significance test}
Kronecker with low dimensions and thus with correlation as the similarity measure gives the highest scores. As the dimensionality increases, Kronecker performance stays constant. Addition is slightly better than multiplication, but the performance of both peaks at 2000 dimensions and decreases as the dimensionality increases.

\texttt{Head} parameters are similar to the lexical Max selection (Table~\ref{tab:lexical-max-selection}), with an exception of \texttt{neg}, where values similar to MEN (Table~\ref{tab:men-max-selection}) are chosen.

All compositional operators agree in the choice of \texttt{freq} ($\log n$), \texttt{discr} (SCPMI) and similarity (correlation, note that Kronecker was tested only with the inner product for $D > 3000$ because of limited computational resources).

Compositional operators perform best with constant \texttt{freq} of 1, in contrast to the lexical setting, where $\log n$ is more beneficial. This might be because during composition the $\log n$ term dominates over the PMI value and minimises its effect.

Local context probabilities perform better in compositional tasks. Multiplication benefits from the unsmoothed distribution probability, while highly dimensional models perform best with smoothing ($\alpha = 0.75$). The only exception are additive models with $D < 5000$, where global probabilities perform best.

For low dimensional spaces, addition performs best with sparse spaces ($k > 1$, $D < 5000$), but for high dimensional spaces, addition performs best  with dense spaces ($k = 0,7$, $D \geq 5000$).

Multiplication, independently of dimensionality, performs best with dense spaces ($k = 0.2$).

Kronecker, in contrast to addition, performs best with dense low dimensional models ($k = 0.2$, $D < 5000$) and sparser high dimensional models ($k = 0.7$, $D \geq 5000$). But this difference might depend on the similarity measure, which is inner product for $D \geq 5000$.

\subsection{Heuristics}
\label{sec:heuristics}

\input{figures/ks14-ablation}

The linear model achieves an $R^2 = 0.794$. The partial $R^2$ are shown on Table~\ref{tab:ks14-ablation}. The most influential parameters are \texttt{neg}, \texttt{freq}, compositional operator and \texttt{cds}. Interestingly, similarity has much less influence on this compositional dataset than on lexical datasets, where for Sim-Lex-999 (Table~\ref{tab:SimLex999-ablation}) and combined (Table~\ref{tab:lexical-ablation}) it is the most influencing parameter. Also, note that dimensionality has the lowest partial $R^2$.

\subsubsection{Shifting}

\input{figures/ks14-neg}
For \texttt{head}, the best \texttt{neg} choice of $k$ is 1 for spaces with dimensionality less than 5000 (Figure~\ref{fig:ks14-neg}). For $5000 \leq D < 30000$, \texttt{head} behaves best with $k = 1.4$ and for $D \geq 3000$ \texttt{neg} should be set to 2.

For addition, spaces with $D < 20000$ should be used with $k = 1.4$, and with $k = 2$ otherwise.

For multiplication as with addition, there are three most beneficial choices: for $D < 10000$ $k = 0.5$, for $10000 \leq D < 30000$ $k = 0.7$ and, finally, for $D > 30000$ $k = 1$.

\todo{See whether the trend ``if small then dense and if big then sparse'' holds.}
Kronecker shows similar behaviour of $k$ as dimensionality increases as multiplication, but prefers sparser spaces: for $D < 3000$ $k = 0.5$, for $3000 \leq D < 20000$ and $D \geq 20000$ $k = 1$.

\subsubsection{Frequency}
The best option of \texttt{freq} for \texttt{head} is $\log n$ (Figure~\ref{fig:ks14-freq}). The constant frequency 1 is very close $\log n$, but its performance declines for spaces with $D > 20000$.

For addition, frequency should be set to 1 for spaces with $D < 5000$ and to $\log n$ otherwise.

There is one choice of frequency for multiplication: 1.

\todo{Check whether \texttt{freq}:n is bad for operators that do multiplication.}
Kronecker follows addition with regard to \texttt{freq}, but the split point is $D = 10000$: low dimensional spaces should be used with constant frequency 1, and high dimensional spaces with $\log n$.

\subsubsection{Context distribution smoothing}

\input{figures/ks14-cds}
\texttt{Head} with spaces with dimensionality less than 20000 should be used with global probabilities, and more dimensional models should be used with smoothed local probabilities: $\alpha = 0.75$ (Figure~\ref{fig:ks14-cds}).

All other operators perform best with global context probability.

\subsubsection{Similarity}
\texttt{Head} with spaces with $D < 20000$ performs best with cosine similarity, while more dimensional models prefer correlation as the similarity measure (Figure~\ref{fig:ks14-similarity}).

Other operators prefer correlation, however its not known correlation and cosine performance with Kronecker with spaces with $D > 3000$ as those were not tested, leaving inner product as the only choice.

\subsubsection{Discriminativeness}

\input{figures/ks14-discr}
\texttt{Head} with $D < 20000$ prefers SCPMI as the discriminativeness weighting. SPMI is preferred otherwise (Figure~\ref{fig:ks14-discr}).

For addition, SPMI is the better choice. For multiplication, SCPMI is more beneficial.

For Kronecker the two choices are very close to each other. However, for spaces with dimensionality less than 20000, SPMI is slightly better; for spaces with greater dimensionality, SCPMI is better.

\subsection{Difference between Max selection and heuristics on KS14}

\todo[noline]{Difference between heuristics based on various datasets.}

Table~\ref{tab:ks14-heuristics-selection}\todo{finish}\ldots

% \input{figures/selection-ks14}

\section{GS11}
\label{sec:gs11}

\todo[inline]{Mention \cite{hashimoto-tsuruoka:2016:P16-1}}

\subsection{Max selection}
\label{sec:max-selection-gs11}

\input{figures/gs11-results}

Figure~\ref{fig:gs14-results} shows performance of the compositional models on the transitive verb disambiguation task \cite{Grefenstette:2011:ESC:2145432.2145580}. Table~\ref{tab:gs11-max-selection} shows the selected model performance together with chosen parameters.

Multiplication with 20000 dimensions gives the highest result of 0.532. Kronecker gets close with the score of 0.516 with $D = 50000$. Addition does not outperform the \texttt{head} operator: addition scores 0.338, while \texttt{head}'s best performance is 0.432.

\texttt{Head}'s behaviour is unstable for dimensions less than 20000, and its best behaviour might be the case of overfitting similarly with SimLex-999. Models with dimensions greater than 20000 behave similarly to each other, even though the parameters are different.

In general, parameter selection is very different than the one based on KS14 (Table~\ref{tab:ks14-max-selection}). Compositional operators behave best with $\log n$ frequency, especially Kronecker. PMI often outperforms other discriminativeness components in case of \texttt{head} and addition. Global context probability estimation behaves better than local. Correlation is not always the best similarity measure.

Addition behaviour degrades as dimensionality increases, multiplication behaviour increases, but becomes unstable for spaces with high number of dimensions. Kronecker depends the least on the dimensionality.

Addition works best with dense models. Multiplication and Kronecker prefer dense low dimensional space and sparse high dimensional spaces.


\subsection{Heuristics}
\label{sec:heuristics-gs11}

The linear model achieves a $R^2 = 0.753$. The partial $R^2$ scores are shown on Table~\ref{tab:gs11-ablation}. The most influential parameters are a compositional operator, \texttt{freq} and \texttt{neg}. This is the same as in case of KS14, but in the reversed order \ref{tab:ks14-ablation}. However, for GS11 the operator choice is the most important, in case of KS14, the partial $R^2$ scores of the top 3 parameters are much closer to each other.

\todo[noline]{wraptable \ref{tab:gs11-ablation}}
\input{figures/gs11-ablation}

\subsubsection{Frequency}

\input{figures/gs11-freq}

$\log n$ on average behaves best for all operators (Figure~\ref{fig:gs11-freq}).

\subsubsection{Shifting}

\texttt{Head} on average works best with shifted models. For models with dimensionality less than 3000, $k = 0.5$, otherwise $k = 0.7$ is more beneficial (Figure~\ref{fig:gs11-neg}).

For addition, models without shifting behaves best for $D < 20000$, however for more dimensional spaces, $k = 0.2$ should be preferred.

Multiplication also works best with unshifted low dimensional spaces ($D < 5000$) and with $k = 0.7$ for high dimensional spaces.

Kronecker prefers shifting. For spaces with dimensionality less then 20000 $k = 0.7$ and $k = 1$ otherwise.

\subsubsection{Similarity}

\input{figures/gs11-similarity}

\texttt{Head} and multiplication work best with cosine similarity. Addition with correlation and Kronecker with inner product (Figure~\ref{fig:gs11-similarity}).

\subsubsection{Context distribution smoothing}

\texttt{Head} with $D < 10000$ works best with global context probabilities. For more dimensional spaces, local context probabilities $\alpha = 1$ should be preferred (Figure~\ref{fig:gs11-cds}).

Addition works best with local probabilities. In the low dimensional case, when $D < 20000$, unsmoothed estimation ($\alpha = 1$) is preferred and $\alpha = 0.75$ should be chosen otherwise.

Multiplication works best with global context probabilities. Kronecker with smoothed local ($\alpha = 0.75$).

\subsubsection{Discriminativeness}

\input{figures/gs11-discr}

\texttt{Head} works best with SPMI, but SCPMI is very close (Figure~\ref{fig:gs11-discr}).

Addition works best with PMI for $D < 20000$ and SCPMI otherwise.

Multiplication is similar to addition that it prefers PMI in the low dimensional case and SCPMI in the high dimensional case, but the change happens at 5000 dimensions.

Kronecker with less than 5000 dimensions prefers SCPMI and SPMI otherwise.

\todo[noline]{Heuristics selection table.}

\subsection{Difference between Max selection and heuristics on GS11}

Only logarithmic frequency component ($\log n$) was chosen by heuristics (Table~\ref{tab:gs11-heuristics-selection}), while there is a mix of 1 and $\log n$ in the Max selection (Table~\ref{tab:gs11-max-selection}).

Kronecker and most of multiplication discriminativeness choices agree, while for \texttt{head} and addition there is little agreement of parameter selection. Same goes for context distribution smoothing and shifting.

Similarity choice is same for Kronecker and addition, but \texttt{head} and multiplication---according to heuristics---should be used with cosine similarity, while there is no single metric that leads to maximum performance.

\section{PhraseRel}
\label{sec:phraserel-experiment}

\todo[inline]{Outdated: heuristics!!!}

\subsection{Max selection}
\label{sec:max-selection-phraserel}

\input{figures/phraserel-results}

Figure~\ref{fig:phraserel-results} shows the performance of the models on the PhraseRel dataset. All operators outperform non-compositional \texttt{head} baseline. Table~\ref{tab:phraserel-max-selection} shows the models that yield the best result together with model parameters.

Multiplication, in general, outperforms all other operators, and with dimensions of 10000 and 20000 gets the perfect score. Model performance weakly depends on the dimensionality for all operators.

Addition and Kronecker achieve the best score with constant frequency, \texttt{head} works best with linear and multiplication with sublinear ($\log n$).

SPMI is the preferred discriminativeness component for the low-dimensional spaces ($D < 10000$) for \texttt{head}, otherwise, SCPMI is the best behaving \texttt{discr}. For addition and the spaces with $D > 1000$, SPMI is the best, while for the spaces with the same dimensionality multiplication prefers CPMI. Kronecker, most of the times, prefers SCPMI.

\texttt{Head} with dimensions less than 20000 works best with local smoothed context probabilities, however for more dimensional spaces global context probabilities are more competitive. Addition, contrary, prefers smoothed local context probabilities for spaces with dimensions more than 5000. Multiplication exhibits different pattern: when a model contains few dimensions, it prefers local smoothed context probabilities, and for highly-dimensional spaces it prefers local, but unsmoothed context probabilities. Kronecker is inconsistent with regards to the choice of \texttt{cds}, but models with $D \geq 30000$ global context probabilities perform the best.

Regarding shifting, \texttt{head} prefers sparse spaces $k > 1$, but as dimensionality increases the optimal $k$ values decreases. Addition does not show a consistent behaviour with regard to this parameter. Multiplication, in general, benefits from dense unshifted spaces. Kronecker works best with sparse spaces with increasing sparsity as the dimensionality increases.

\texttt{Head} benefits from the correlation as the similarity measure, as does multiplication. Addition works best with correlation with spaces $D < 10000$, and with the inner product for more dimensional spaces. Multiplication works best with correlation. Kronecker, for spaces with less than 5000 dimensions, works best with correlation and with the inner product otherwise.

\subsection{Heuristics}
\label{sec:heuristics-phraserel}

\input{figures/phraserel-ablation}

\input{figures/phraserel-neg}
The linear model achieves an $R^2 = 0.856$. The partial $R^2$ scores are shown on Table~\ref{tab:phraserel-ablation}. The most influential parameters are \texttt{neg}, operator and \texttt{cds}, but the first two have the partial $R^2$ scores much higher then the other parameters. Table~\ref{tab:phraserel-heuristics-selection} shows the performance of the picked models.

\subsubsection{Shifting}
\label{sec:shifting-phraserel}

\texttt{Head} should be used with $k = 1.4$, addition should be used with $k = 2$ and multiplication should be used with $k = 0.5$ (Figure~\ref{fig:phraserel-neg}).

Kronecker has three optimal values of $k$ that is proportional to dimensionality. For models with dimensionality less than 5000, $k = 0.5$ is preferred; for $5000 \geq D < 20000$, the most beneficial choice of \texttt{neg} is $k = 1$; finally, for spaces with more than 20000 dimensions, $k$ should be set to 1.4.

\subsubsection{Context distribution smoothing}
\label{sec:cont-distr-smooth-phraserel}

The best choice of \texttt{head} is dependant on dimensionality: spaces with less than 10000 dimensions benefit from smoothed local context probabilities ($\alpha = 0.75$) (Figure~\ref{fig:phraserel-cds}). Addition and multiplication work best with global context probabilities, while Kronecker prefers unsmoothed local probabilities ($\alpha = 1$).

\subsubsection{Frequency}
\label{sec:frequency-phraserel}

\input{figures/phraserel-freq}

\texttt{Head} works best with linear frequency, but the difference with other options is small (Figure~\ref{fig:phraserel-freq}).

Addition benefits from linear frequency, sublinear frequency is very close.

Multiplication works best with sublinear frequency, but linear is very close to it.

Finally, Kronecker works best with $\log n$ with spaces with dimensionality less than 5000, and with linear frequency with more dimensional spaces.

\subsubsection{Similarity}
\label{sec:similarity-phraserel}

\texttt{Head} works best with correlation as the similarity measure with models with $D < 5000$, and with cosine for more dimensional ones (Figure~\ref{fig:phraserel-similarity}). Note, however, that the difference between the two is very small.

Addition benefits from cosine when $D < 20000$ and from inner product otherwise. But in case of addition, all three similarity measures are close to each others.

Multiplication works best with correlation.

Where tested, correlation behaves best with Kronecker.

\subsubsection{Discriminativeness}
\label{sec:discriminativeness-phraserel}

\input{figures/phraserel-discr}

\texttt{Head} is the only ``operator'' that prefers from different discriminativeness components depending on dimensionality. For models with $D < 5000$, SPMI is the best, while for other dimensions SCPMI is more competitive.

Addition and Kronecker benefit from SPMI, while multiplication from SCPMI.

\subsection{Difference between Max selection and heuristics on PhraseRel}
\label{sec:diff-phraserel}

Manual parameter selection is more stable than the one based on the maximum values. However in cases where different parameters are picked, there is little or no difference between these parameter choices. For example studied similarity measures yield similar average performance for addition, see Figure~\ref{fig:phraserel-freq}.

Manual heuristics do not pick the best result of 1 (Table~\ref{tab:phraserel-max-selection}), but are close with a multiplicative model with 20000 and 30000 dimensions yielding the score of 0.964 (Table~\ref{tab:phraserel-heuristics-selection}).

The average relative difference between the max selection and the selection based on heuristics is 0.022 for \texttt{head}, 0.072 for addition, 0.041 for multiplication and 0.061 for Kronecker.

\section{Selected model transfer across the datasets}
\label{sec:select-model-transf-comp}

\subsection{Difference between heuristics}
\label{sec:diff-betw-heur-comp}

There is little agreement on parameter selection based on heuristics among the 3 compositional datasets. The only consistent choice is global context probability (\texttt{cds}) and SCPMI discriminativeness for multiplicative models.

There is more pairwise agreement, for example similarity based on correlation for additive models on KS14 and GS11 and $\log n$ frequency for multiplicative models between GS11 and PhraseRel. The pairwise agreement might be a sign of overfitting, because there is no clear pattern. On the other side, the difference in performance between parameter choices might be neglectable as some parameters consistently show low $R^2$ scores, for example \texttt{discr}.

\subsection{From KS14}
\label{sec:from-ks14}

\input{figures/ks14-transfer}

Figure~\ref{fig:ks14-transfer} show the behaviour of models selected on the KS14 when they are transferred to GS11 and PhraseRel. During the transfer there is little difference in performance between the selection methods, except of multiplicative models where heuristics show better performance and 5000 dimensional Kronecker where heuristics give lower results than the max-based selection.

\todo[noline]{Significance tests}
Heuristic-based selecting on average is closer to the upper bound. When transferred to GS11 the average difference with the upper bound is 0.335 for max and 0.238 for heuristics. When transferred to PhraseRel the average difference is 0.093 for max and 0.091 for heuristics.

\subsection{From GS11}
\label{sec:from-gs11}

\input{figures/gs11-transfer}

Figure~\ref{fig:gs11-transfer} shows that there is little difference between max and heuristic selections. In case of \texttt{head} composition, heuristics lead to higher performance, while for low-dimensional multiplicative models heuristics fall behind the max selection on the KS14 dataset.

\todo[noline]{Significance tests}
When GS11 models are transferred to KS14, the average difference with the upper bound is 0.119 and 0.106 for max and heuristics respectively. For the transfer to PhraseRel, the differences are 0.133 for max and 0.188 for heuristics. Again, the heuristic-based selection outperforms the max based.

\subsection{From PhraseRel}
\label{sec:from-phraserel}

\input{figures/phraserel-transfer}

Figure~\ref{fig:phraserel-transfer} shows that the performance of models based on PhraseRel is less stable, especially for selection by maximum performance.

\todo[noline]{Significance tests}
Transfer to KS14 yields the average differences of 0.152 for max and 0.136 for heuristics. Transfer to GS11 yields the average differences of 0.454 for max and 0.509 for heuristics. Note that the PhraseRel to GS11 transfer is the only case where max selection on average is better than heuristics.

\todo[inline]{Here we showed, in contrast to the lexical evaluation, that the heuristics might be indeed be more beneficial than the max-based selection.}

\section{Universal parameter selection for compositional datasets}
\label{sec:robust-param-comp-selecion}

\input{figures/compositional-results}

Figure~\ref{fig:compositional-results} show the performance of the models based on the combined selection over the KS14, GS11 and PhraseRel datasets. The performance of selected models together with the selected parameters is shown on the Table~\ref{tab:compositional-max-selection} (Max selection) and Table~\ref{tab:compositional-heuristics-selection} (selection based on heuristics).

\subsection{Max selection}
\label{sec:max-selection-compositional}

Models with many dimensions not always perform better than their low-dimensional counterparts. Particularly, only \texttt{head} and multiplication benefit from the high number of dimensions. Addition and Kronecker are closer to the upper bound with the dimensionality of few thousands.

\subsection{Heuristics}
\label{sec:heuristics-compositional}

\input{figures/compositional-ablation}
The linear model achieves the $R^2 = 0.769$. Table~\ref{tab:compositional-ablation} shows the partial $R^2$ values for the parameters. The most influential parameters are \texttt{neg}, \texttt{freq} and compositional operator.

\subsubsection{Neg}
\label{sec:neg-compositional}

\input{figures/compositional-neg}

For \texttt{head} and models with $D < 10000$ the \texttt{neg} should be set to 1, otherwise it should be 1.4 (Figure~\ref{fig:compositional-neg}).

For addition, 1 is the best choice of \texttt{neg}.

Multiplication benefits from denser spaces. If the dimensionality is less than 10000, then \texttt{neg} should be set to 0.5, otherwise 0.7 is a good choice.

Kronecker benefits from the \texttt{neg} of 0.7 if $D < 10000$ and from 1 for the more dimensional cases. This is similar to multiplication, but Kronecker prefers less dense vectors.

\subsubsection{Freq}
\label{sec:freq-compositional}

$\log n$ is the frequency value of choice of all operators with an exception of multiplication, where the constant frequency is preferred (Figure~\ref{fig:compositional-freq}).

\subsubsection{Context distribution smoothing}
\label{sec:cont-distr-smooth-compositional}

\input{figures/compositional-cds}

As Figure~\ref{fig:compositional-cds} shows, global context probability is the preferred choice of context probability in all cases, but in cases of Kronecker composition with $D > 3000$, where smoothed local probabilities are better ($\alpha = 0.75$).

\subsubsection{Similarity}
\label{sec:similarity-compositional}

Correlation is the dominant choice of the similarity measure (Figure~\ref{fig:compositional-similarity}). However, cosine is preferred in the case of \texttt{head}, with $D > 5000$, and inner product is the only choice for the composition with Kronecker with $D > 3000$.

\subsubsection{Discr}
\label{sec:discr-compositional}

\input{figures/compositional-discr}

SPMI is the choice of \texttt{discr} that leads to the best average performance in most cases (Figure~\ref{fig:compositional-discr}). However the difference between SPMI and SCPMI is very small.

The exceptions are Multiplicative composition with $D \geq 10000$ and Kronecker with $D \leq 5000$ where SCPMI outperforms SPMI.

\subsection{Comparison with the single dataset beased selections}
\label{sec:comp-with-single-comp}

Manual selection based on a combination of the compositional datasets is more stable with regards to the chosen parameter values than the selection based on the highest values, even though manual selection does not always achieve the performance of Max selection, see Figure~\ref{fig:compositional-results}.

The average difference with the upper bound is 0.040 and 0.041 for Max and heuristics, respectively, when applied to KS14. For GS11, the difference is 0.045 (Max) and 0.127 (Heuristics). For PhraseRel, the difference is 0.055 (Max) and 0.084 (Heuristics).

\chapter[Universal model]{Universal model for both lexical and compositional tasks}
\label{sec:universal-param-selection}

\todo[inline]{From lexical to compositional.}

\section{Operator dependant (universal) models}
\label{sec:model-selection}

\subsection{Max selection}
\label{sec:max-selection-universal}

Table~\ref{tab:universal-max-selection} shows the performance of the models selected by a combined score of the lexical and compositional datasets. Parameter selection is much more stable than on all previous max-based selections. $\log n$ is a dominant \texttt{freq} choice, cosine is the measure of choice for multiplication and Kronecker, if available. Correlation is the similarity measure for additive composition. Interestingly, if shifting applied, then 1 or 0.7 are chosen as \texttt{neg} values.

\todo[noline]{This is one of the major findings.}
Compositional operator preference depends on the focus of a model.
Addition with many dimensions gives the best results on lexical tasks: 0.384 on SimLex-999 and 0.761 on MEN. Kronecker, on the other side, gives the highest values for compositional datasets: 0.798 on KS14, 0.514 on GS11 and 0.964 on PhraseRel. Multiplication, however, gives the highest ``combined'' score of 0.945, showing that the selection is the closest to the upper bound.

\subsection{Heuristics}
\label{sec:heuristics-universal}

\input{figures/universal-ablation}

Performance of the models selected manually shown on Table~\ref{tab:universal-heuristics-selection}. Again, there is a lot consistency between parameters. The linear model achieves $R^2 = 0.828$. The most influencing parameters are \texttt{freq}, \texttt{neg} and a similarity measure, refer to Table~\ref{tab:universal-ablation}.

Heuristics for addition choose models that score the highest on lexical tasks: 0.384 on SimLex-999 and 0.764 on MEN (Table~\ref{tab:universal-heuristics-selection}). Moreover, with more than 20000 dimensions there is no difference between the selection procedures (Max or heuristics) of the additive and Kronecker-based models.

Kronecker is strong in compositional tasks scoring 0.795 on KS14, 0.516 on GS11 and 0.929 on PhraseRel (Table~\ref{tab:universal-heuristics-selection}).

Multiplication, again, is a compromise between the two: it gives the highest combined score of 0.941. The highest Kronecker's combined is 0.913, while addition's highest score is only 0.843.

\subsection{Comparison}
\label{sec:comparison-universal}

\input{figures/universal-results}

On lexical tasks, there is little difference between the model selection methods especially for spaces with more than 30000 dimensions, as Figures~\ref{fig:universal-results-simlex} and \ref{fig:universal-results-men} show.

On compositional tasks, dimensionality does not contribute as much as in case of lexical tasks, with an exception of addition on the GS11 dataset, where performance decreases as dimensionality increases.

\todo[noline]{One of the major findings.}
When the models that are selected on lexical tasks are applied in a compositional setting, they perform worse than the models selected based on the universal score. This suggests that a model that is good on lexical tasks will not necessarily perform well on a compositional task. In addition, sometimes this difference increases as dimensionality increases, for example this is the case for multiplication, the most notable difference is observed on KS14 (Figure~\ref{fig:universal-results-ks14}).

\todo[inline]{Compare the average differences of every dataset.}

\section{Operator independant universal models}

\todo[inline]{We have seen in the previous section that even though parameter selection is different between operators, there are choices that are shared. Given this and the fact that the difference between some of the choices is marginal, we try to look for truly universal parameters.}

\subsection{Max selection}
\label{sec:max-selection-single}

Table~\ref{tab:single-max-selection} shows \todo{describe how it was combined} the combined score for all datasets abstracting over a compositional operator.

The parameter selection shows a clear pattern. \texttt{freq} shows a clear pattern: low-dimensional spaces perform best with 1 as the frequency choice, while high dimensional models perform better with $\log n$. Cosine is a better suited similarity measure for models with few dimensions, correlation with many. Finally, global context probabilities are the best in a low-dimensional case, while local context probabilities perform best with many dimensions.

\todo[inline]{Average difference with the upper bound.}

\subsection{Heuristics}
\label{sec:heuristics-single}

Heuristics in general repeat the parameter selection choice, but the switch happens with more dimensions (at 20000, not at 5000) refer to Table~\ref{tab:single-heuristics-selection} for the results and Figure~\ref{fig:single-params} for the parameter behavior.

\input{figures/single-ablation}
The linear model gives $R^2 = 898$. The most influential parameters are \texttt{freq}, similarity measure and \texttt{neg}, refer to Table~\ref{tab:single-ablation}.

\input{figures/single-freq}

% \subsubsection{Tweaked IR evaluation}
% \label{sec:tweak-ir-eval}

% \todo[inline]{Discuss \cite{Milajevs:2015:IMN:2808194.2809448} and link to \ref{sec:phraserel}}

% \section{PhraseRel: relevance of sentences}
% \label{sec:sentential-relevance}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
