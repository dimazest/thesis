\chapter{Relationships between sentences}
\label{sec:sentential}

\todo[inline]{Selection description: global best; best operator, its general behaviour, general behaviour of others; parameters.}

\section{Elaborated hypotheses}
\label{sec:elab-hypoth-comp}

As for the lexical experiments (Section~\ref{sec:elab-hypoth-lexical}), before reporting the results we refine some of our initial hypothesis (Section~\ref{sec:hypotheses}).

\begin{hyp}[H\ref{hyp:comp-pmi-cpmi}]
  \label{hyp:comp-pmi-cpmi}
  Compositional methods based on addition perform best with either PMI or SPMI, while methods that are based on multiplication should work best with CPMI and SCPMI.
\end{hyp}

The reason for that is the presence of negative values. In case of multiplication as a compositional operator, the sign of a vector component depends on the number of the corresponding negative components of the constituents. If the number of negative values is odd, then the resulting value will be negative. This makes the difference between 0.001 and -0.001 significant, while in the first case the value means that the co-occurrence pair is weakly associated, but in the second case the value means that the co-occurrence is weakly unassociated.

We also expect hypotheses related to PMI's Achilles heel (H\ref{hyp:freq}, H\ref{hyp:cds}, H\ref{hyp:neg}) to apply in the compositional case.

\begin{hyp}[H\ref{hyp:similarity}]
  \label{hyp:similarity}
  Cosine is an optimal similarity measure for low-dimensional spaces, while correlation is for highly-dimensional spaces.
\end{hyp}

We observed such behaviour in lexical tasks (Section~\ref{sec:conclusion-lexical}) and expect to see similar behaviour in compositional tasks.

\section{KS14}
\label{sec:ks14}

\subsection{Max selection}
\label{sec:max-selection-ks14}

\input{figures/ks14-results}

Figure~\ref{fig:ks14-results} shows the performance of compositional model on the sentence similarity dataset KS14 \cite{kartsadrqpl2014}. All operators outperform the non-compositional \texttt{head} operator. Table~\ref{tab:ks14-max-selection} shows the performance of models selected by Max selection together with the selected parameters.

\todo[noline]{Significance test}
Kronecker with few thousand dimensions and correlation as the similarity measure gives the highest scores, supporting H\ref{hyp:order}. As the dimensionality increases, Kronecker performance stays constant. Addition is slightly better than multiplication, but the performance of both peaks at 2000 dimensions and decreases as the dimensionality increases.

\texttt{Head} parameters are similar to the lexical Max selection (Table~\ref{tab:lexical-max-selection}), with an exception of \texttt{neg}, where values similar to MEN (Table~\ref{tab:men-max-selection}) are chosen.

All compositional operators agree in the choice of \texttt{freq} ($\log n$), \texttt{discr} (SCPMI) and similarity (correlation, note that Kronecker was tested only with the inner product for $D > 3000$ because of limited computational resources).

Compositional operators perform best with constant \texttt{freq} of 1, in contrast to the lexical setting, where $\log n$ is more beneficial. This might be because during composition the $\log n$ term dominates over the PMI value and minimises its effect.

Local context probabilities perform better in compositional tasks. Multiplication benefits from the unsmoothed distribution probability, while highly dimensional models perform best with smoothing ($\alpha = 0.75$), supporting H\ref{hyp:cds}. The only exception are additive models with $D < 5000$, where global probabilities perform best.

For low dimensional spaces, addition performs best with sparse spaces ($k > 1$, $D < 5000$), but for high dimensional spaces, addition performs best  with dense spaces ($k = 0,7$, $D \geq 5000$), supporting H\ref{hyp:neg}.

Multiplication, independently of dimensionality, performs best with dense spaces ($k = 0.2$).

Kronecker, in contrast to addition, performs best with dense low dimensional models ($k = 0.2$, $D < 5000$) and sparser high dimensional models ($k = 0.7$, $D \geq 5000$). However, this difference might be explained by the change of the similarity measure, which is inner product for $D \geq 5000$.

\subsection{Heuristics}
\label{sec:heuristics}

\input{figures/ks14-ablation}

The linear model achieves an $R^2 = 0.794$. The partial $R^2$ are shown on Table~\ref{tab:ks14-ablation}. The most influential parameters are \texttt{neg}, \texttt{freq}, compositional operator and \texttt{cds}. Interestingly, similarity has much less influence on this compositional dataset than on lexical datasets, where for Sim-Lex-999 (Table~\ref{tab:SimLex999-ablation}) and combined (Table~\ref{tab:lexical-ablation}) it is the most influencing parameter. Also, note that dimensionality has the lowest partial $R^2$.

\subsubsection{Shifting}

\input{figures/ks14-neg}
For \texttt{head}, the best \texttt{neg} choice of $k$ is 1 for spaces with dimensionality less than 5000 (Figure~\ref{fig:ks14-neg}). For $5000 \leq D < 30000$, \texttt{head} behaves best with $k = 1.4$ and for $D \geq 3000$ \texttt{neg} should be set to 2.

For addition, spaces with $D < 20000$ should be used with $k = 1.4$, and with $k = 2$ otherwise.

For multiplication, there are three most beneficial choices: for $D < 10000$ $k = 0.5$, for $10000 \leq D < 30000$ $k = 0.7$ and, finally, for $D > 30000$ $k = 1$.

Kronecker shows similar behaviour of $k$ as dimensionality increases as multiplication, but prefers sparser spaces: for $D < 3000$ $k = 0.5$, for $3000 \leq D < 20000$ and $D \geq 20000$ $k = 1$.

All operators behave in accordance to H\ref{hyp:neg}.

\subsubsection{Frequency}
The best option of \texttt{freq} for \texttt{head} is $\log n$ (Figure~\ref{fig:ks14-freq}). The constant frequency 1 is very close $\log n$, but its performance declines for spaces with $D > 20000$.

For addition, frequency should be set to 1 for spaces with $D < 5000$ and to $\log n$ otherwise.

There is one choice of frequency for multiplication: 1, however $\log n$ behaves similarly to it for large values of $D$.

Kronecker follows addition with regard to \texttt{freq}, but the split point is $D = 10000$: low dimensional spaces should be used with constant frequency 1, and high dimensional spaces with $\log n$.

Therefore, H\ref{hyp:freq} is supported by this dataset.

\subsubsection{Context distribution smoothing}

\input{figures/ks14-cds}
\texttt{Head} with spaces with dimensionality less than 20000 should be used with global probabilities, and more dimensional models should be used with smoothed local probabilities: $\alpha = 0.75$ (Figure~\ref{fig:ks14-cds}).

All other operators perform best with global context probability. Even though local context probability with $\alpha = 1$ is close to it, H\ref{hyp:cds} is not supported by this dataset.

\subsubsection{Similarity}
\texttt{Head} on spaces with $D < 20000$ performs best with cosine similarity, while more dimensional models prefer correlation as the similarity measure (Figure~\ref{fig:ks14-similarity}).

Other operators work best with correlation. Only addition supports H\ref{hyp:similarity}. In case of multiplication, correlation dominates over cosine even for small values of $D$. There is little to say about Kronecker, as it is tested only with the inner product for spaces with $D > 3000$ due to its computational complexity ($\mathcal{O}(n^2)$ with respect to the number of vector components).

\subsubsection{Discriminativeness}

\input{figures/ks14-discr}
\texttt{Head} with $D < 20000$ prefers SCPMI as the discriminativeness weighting. SPMI is preferred otherwise (Figure~\ref{fig:ks14-discr}).

For addition, SPMI is the better choice. For multiplication, SCPMI is more beneficial, as expected by H\ref{hyp:comp-pmi-cpmi}.

For Kronecker, the two choices are very close to each other. However, for spaces with dimensionality less than 20000, SPMI is slightly better; for spaces with greater dimensionality, SCPMI is better.

\subsection{Difference between Max selection and heuristics on KS14}

Table~\ref{tab:ks14-heuristics-selection} shows the selection based on heuristics, which is more homogeneous than the selection based on the highest score (Table~\ref{tab:ks14-max-selection}). Both methods agree on the similarity choice (with an exception of \texttt{head}).

Multiplication agrees on the majority of parameters, but \texttt{cds} and \texttt{neg}. Local probabilities ($\alpha = 1$) and $k = 0.2$ give the highest score, while manual selection picked global context probabilities with \texttt{neg} in range on 0.5 to 1, in accordance to H\ref{hyp:neg}.

The average difference between Max and heuristic-based selections is 0.022. Per operator, the differences are: 0.028 \texttt{head}, 0.012 addition, 0.018 multiplication and 0.028 Kronecker. All the values are within the 10\% set by H\ref{hyp:10percent}.

\section{GS11}
\label{sec:gs11}

\todo[inline]{Mention \cite{hashimoto-tsuruoka:2016:P16-1}}

\subsection{Max selection}
\label{sec:max-selection-gs11}

\input{figures/gs11-results}

Figure~\ref{fig:gs14-results} shows performance of the compositional models on the transitive verb disambiguation task \cite{Grefenstette:2011:ESC:2145432.2145580}. Table~\ref{tab:gs11-max-selection} shows the selected model performance together with chosen parameters.

Multiplication with 20000 dimensions gives the highest result of 0.532. Kronecker gets close with the score of 0.516 with $D = 50000$, giving no support to H\ref{hyp:order}. Addition does not outperform the \texttt{head} operator: addition scores 0.338, while \texttt{head}'s best performance is 0.432.

\texttt{Head}'s behaviour is unstable for dimensions less than 20000, and its best behaviour might be the case of overfitting similarly with SimLex-999. Models with dimensions greater than 20000 behave similarly to each other, even though the parameters are different.

In general, parameter selection is very different than the one based on KS14 (Table~\ref{tab:ks14-max-selection}). Compositional operators behave best with $\log n$ frequency, especially Kronecker. PMI often outperforms other discriminativeness components in case of \texttt{head} and addition. Global context probability estimation behaves better than local. Correlation is not always the best similarity measure.

Addition behaviour degrades as dimensionality increases, multiplication behaviour increases, but becomes unstable for spaces with high number of dimensions. Kronecker depends the least on the dimensionality.

Addition works best with dense models. Multiplication and Kronecker prefer dense low dimensional space and sparse high dimensional spaces, supporting H\ref{hyp:neg}.

\subsection{Heuristics}
\label{sec:heuristics-gs11}

\input{figures/gs11-ablation}

The linear model achieves an $R^2 = 0.753$. The partial $R^2$ scores are shown on Table~\ref{tab:gs11-ablation}. The most influential parameters are a compositional operator, \texttt{freq} and \texttt{neg}. This is the same as in case of KS14, but in the reversed order (Table~\ref{tab:ks14-ablation}).


\subsubsection{Frequency}

\input{figures/gs11-freq}

$\log n$ on average behaves best for all operators (Figure~\ref{fig:gs11-freq}). For $D \leq 5000$, 1 is also a good frequency choice, supporting H\ref{hyp:freq}.

\subsubsection{Shifting}

\texttt{Head} on average works best with shifted models. For models with dimensionality less than 3000, $k = 0.5$, otherwise $k = 0.7$ is more beneficial (Figure~\ref{fig:gs11-neg}).

For addition, models without shifting behaves best for $D < 20000$, however for more dimensional spaces, $k = 0.2$ should be preferred. This is a weak support of H\ref{hyp:neg}, because unshifted spaces can be seen as shifted with a very small $\alpha$ value.

Multiplication also works best with unshifted low dimensional spaces ($D < 5000$) and with $k = 0.7$ for high dimensional spaces, supporting H\ref{hyp:neg}.

Kronecker prefers shifting. For spaces with dimensionality less then 20000 $k = 0.7$ and $k = 1$ otherwise. This is according to H\ref{hyp:neg}.

\subsubsection{Similarity}

\input{figures/gs11-similarity}

\texttt{Head} and multiplication work best with cosine similarity. Addition with correlation and Kronecker with inner product (Figure~\ref{fig:gs11-similarity}).

Addition strictly supports H\ref{hyp:similarity}, while multiplication supports it by behaving similarity with cosine and correlation.

\subsubsection{Context distribution smoothing}

\texttt{Head} with $D < 10000$ works best with global context probabilities. For more dimensional spaces, local context probabilities $\alpha = 1$ should be preferred (Figure~\ref{fig:gs11-cds}).

Addition works best with local probabilities. In the low dimensional case, when $D < 20000$, unsmoothed estimation ($\alpha = 1$) is preferred and $\alpha = 0.75$ should be chosen otherwise.

Multiplication works best with global context probabilities. Kronecker with smoothed local ($\alpha = 0.75$).

There is no support of H\ref{hyp:cds} because global context probabilities outperform other choices for multiplication, addition behaves the same with all options and Kronecker works best with $\alpha = 0.75$.

\subsubsection{Discriminativeness}

\input{figures/gs11-discr}

\texttt{Head} works best with SPMI, but SCPMI is very close (Figure~\ref{fig:gs11-discr}).

Addition works best with PMI for $D < 20000$ and SCPMI otherwise.

Multiplication is similar to addition that it prefers PMI in the low dimensional case and SCPMI in the high dimensional case, but the change happens at 5000 dimensions.

Kronecker with less than 5000 dimensions prefers SCPMI and SPMI otherwise.

This dataset does not give evidence to support H\ref{hyp:comp-pmi-cpmi}.

\subsection{Difference between Max selection and heuristics on GS11}

Only logarithmic frequency component ($\log n$) was chosen by heuristics (Table~\ref{tab:gs11-heuristics-selection}), while there is a mix of 1 and $\log n$ in the Max selection (Table~\ref{tab:gs11-max-selection}).

Kronecker and most of multiplication discriminativeness choices agree, while for \texttt{head} and addition there is little agreement between parameter selection. Same goes for context distribution smoothing and shifting.

Similarity choice is the same for Kronecker and addition, but \texttt{head} and multiplication---according to heuristics---should be used with cosine similarity, while there is no single metric that leads to maximum performance.

The overall average normalised difference in results between Max and heuristic-based selections is 0.054. Per operator, the differences are: 0.090 \texttt{head}, 0.077 addition, 0.043 multiplication and 0.006 Kronecker. All the values are within the 10\% boundary (H\ref{hyp:10percent}).

\section{PhraseRel}
\label{sec:phraserel-experiment}

\subsection{Max selection}
\label{sec:max-selection-phraserel}

\input{figures/phraserel-results}

Figure~\ref{fig:phraserel-results} shows the performance of the models on the PhraseRel dataset. All operators outperform the non-compositional \texttt{head} baseline. Table~\ref{tab:phraserel-max-selection} shows the models that yield the best result together with model parameters.

Multiplication, in general, outperforms all other operators, and with the dimensions of 10000 and 20000 gets the perfect score, giving no support of H\ref{hyp:order}. Model performance weakly depends on the dimensionality for all operators.

Addition and Kronecker achieve the best score with constant frequency, \texttt{head} works best with linear and multiplication with sublinear ($\log n$) frequency.

SPMI is the preferred discriminativeness component for the low-dimensional spaces ($D < 10000$) for \texttt{head}, otherwise, SCPMI is the best behaving \texttt{discr}. For addition and the spaces with $D > 1000$, SPMI is the best, while for the spaces with the same dimensionality multiplication prefers CPMI, which is inline with H\ref{hyp:comp-pmi-cpmi}. Kronecker, most of the times, prefers SCPMI.

\texttt{Head} with dimensions less than 20000 works best with local smoothed context probabilities, however for more dimensional spaces global context probabilities are more competitive. Addition, contrary, prefers smoothed local context probabilities for spaces with dimensions more than 5000. Multiplication exhibits different pattern: when a model contains few dimensions, it prefers local smoothed context probabilities, and for highly-dimensional spaces it prefers local, but unsmoothed context probabilities, contrary H\ref{hyp:cds}. Kronecker is inconsistent with regards to the choice of \texttt{cds}, but models with $D \geq 30000$ global context probabilities perform the best.

Regarding shifting, \texttt{head} prefers sparse spaces $k > 1$, but as dimensionality increases the optimal $k$ values decreases. Addition does not show a consistent behaviour with regard to this parameter. Multiplication, in general, benefits from dense unshifted spaces. Kronecker works best with sparse spaces with increasing sparsity as the dimensionality increases, supporting H\ref{hyp:neg}.

\texttt{Head} benefits from the correlation as the similarity measure, as does multiplication. Addition works best with correlation with spaces $D < 10000$, and with the inner product for more dimensional spaces. Multiplication works best with correlation. Kronecker, for spaces with less than 5000 dimensions, works best with correlation and with the inner product otherwise.

\subsection{Heuristics}
\label{sec:heuristics-phraserel}

\input{figures/phraserel-ablation}

\input{figures/phraserel-neg}
The linear model achieves an $R^2 = 0.822$. The partial $R^2$ scores are shown on Table~\ref{tab:phraserel-ablation}. The most influential parameters are \texttt{neg}, operator and \texttt{cds}, but the first two have the partial $R^2$ scores much higher then the other parameters. Table~\ref{tab:phraserel-heuristics-selection} shows the performance of the picked models.

\subsubsection{Shifting}
\label{sec:shifting-phraserel}

\texttt{Head} should be used with $k = 1.4$, addition should be used with $k = 2$ and multiplication should be used with $k = 0.5$ (Figure~\ref{fig:phraserel-neg}).

Kronecker has three optimal values of $k$ that is proportional to dimensionality. For models with dimensionality less than 5000, $k = 0.5$ is preferred; for $5000 \geq D < 20000$, the most beneficial choice of \texttt{neg} is $k = 1$; finally, for spaces with more than 20000 dimensions, $k$ should be set to 1.4, which supports H\ref{hyp:neg}.

\subsubsection{Context distribution smoothing}
\label{sec:cont-distr-smooth-phraserel}

The best choice of \texttt{head} is dependant on dimensionality: spaces with less than 10000 dimensions benefit from smoothed local context probabilities ($\alpha = 0.75$) (Figure~\ref{fig:phraserel-cds}). Addition and multiplication work best with global context probabilities, while Kronecker prefers unsmoothed local probabilities ($\alpha = 1$).

\subsubsection{Frequency}
\label{sec:frequency-phraserel}

\input{figures/phraserel-freq}

\texttt{Head} works best with linear frequency, but the difference with other options is small (Figure~\ref{fig:phraserel-freq}).

Addition benefits from linear frequency, sublinear frequency is very close.

Multiplication works best with sublinear frequency, but linear is very close to it.

Finally, Kronecker works best with $\log n$ with spaces with dimensionality less than 5000, and with linear frequency with more dimensional spaces.

In general, H\ref{hyp:freq} holds, because there is no difference between 1 and $\log n$ choices in model performance.

\subsubsection{Similarity}
\label{sec:similarity-phraserel}

For all operators there is little difference between cosine and correlation, weakly supporting H\ref{hyp:similarity}.

\texttt{Head} works best with correlation as the similarity measure with models with $D < 5000$, and with cosine for more dimensional ones (Figure~\ref{fig:phraserel-similarity}). Note, however, that the difference between the two is very small.

Addition benefits from cosine when $D < 20000$ and from inner product otherwise. But in case of addition, all three similarity measures are close to each others.

Multiplication works best with correlation. Where tested, correlation behaves best with Kronecker.

\subsubsection{Discriminativeness}
\label{sec:discriminativeness-phraserel}

\input{figures/phraserel-discr}

\texttt{Head} is the only ``operator'' that prefers from different discriminativeness components depending on dimensionality. For models with $D < 5000$, SPMI is the best, while for other dimensions SCPMI is more competitive.

Addition and Kronecker benefit from SPMI, while multiplication from SCPMI, which supports H\ref{hyp:comp-pmi-cpmi}.

\subsection{Difference between Max selection and heuristics on PhraseRel}
\label{sec:diff-phraserel}

Manual parameter selection is more stable than the one based on the maximum values. However in cases where different parameters are picked, there is little or no difference between these parameter choices. For example studied similarity measures yield similar average performance for addition, see Figure~\ref{fig:phraserel-freq}.

Manual heuristics do not pick the best result of 1 (Table~\ref{tab:phraserel-max-selection}), but are close with a multiplicative model with 20000 and 30000 dimensions yielding the score of 0.964 (Table~\ref{tab:phraserel-heuristics-selection}).

The average relative difference between the max selection and the selection based on heuristics is 0.022 for \texttt{head}, 0.072 for addition, 0.041 for multiplication and 0.061 for Kronecker.

Overall, the difference is 0.049, which is within H\ref{hyp:10percent}.

\section{Selected model transfer across the datasets}
\label{sec:select-model-transf-comp}

\subsection{Difference between heuristics}
\label{sec:diff-betw-heur-comp}

There is little agreement on parameter selection based on heuristics among the 3 compositional datasets. The only consistent choice is global context probability (\texttt{cds}) and SCPMI discriminativeness for multiplicative models.

There is more pairwise agreement, for example similarity based on correlation for additive models on KS14 and GS11 and $\log n$ frequency for multiplicative models between GS11 and PhraseRel. The pairwise agreement might be a sign of overfitting, because there is no clear pattern. On the other side, the difference in performance between parameter choices might be neglectable as some parameters consistently show low $R^2$ scores, for example \texttt{discr}. Consequently, there is inconsistency in the hypotheses support.

\subsection{From KS14}
\label{sec:from-ks14}

\input{figures/ks14-transfer}

Figure~\ref{fig:ks14-transfer} show the behaviour of models selected on the KS14 when they are transferred to GS11 and PhraseRel. During the transfer there is little difference in performance between the selection methods, except of multiplicative models where heuristics show better performance and 5000 dimensional Kronecker where heuristics give lower results than the max-based selection.

\todo[noline]{Significance tests}
Heuristic-based selection on average is closer to the upper bound than max based selection, supporting H\ref{hyp:overfitting}. However, both of them are beyond the 10\% boundary set by H\ref{hyp:10percent}. When transferred to GS11 the average difference with the upper bound is 0.335 for max and 0.238 for heuristics. When transferred to PhraseRel the average difference is 0.093 for max and 0.091 for heuristics.

\subsection{From GS11}
\label{sec:from-gs11}

\input{figures/gs11-transfer}

Figure~\ref{fig:gs11-transfer} shows that there is little difference between max and heuristic-based selections. In case of \texttt{head} composition, heuristics lead to higher performance, while for low-dimensional multiplicative models heuristics fall behind the max selection on the KS14 dataset.

\todo[noline]{Significance tests}
When GS11 models are transferred to KS14, the average difference with the upper bound is 0.119 and 0.106 for max and heuristics respectively. For the transfer to PhraseRel, the differences are 0.133 for max and 0.188 for heuristics. Again, the heuristic-based selection outperforms the max based. This supports H\ref{hyp:overfitting}, but the results are beyond the limit of H\ref{hyp:10percent}.

\subsection{From PhraseRel}
\label{sec:from-phraserel}

\input{figures/phraserel-transfer}

Figure~\ref{fig:phraserel-transfer} shows that the performance of models based on PhraseRel is less stable, especially for selection by maximum performance.

\todo[noline]{Significance tests}
Transfer to KS14 yields the average differences of 0.152 for max and 0.136 for heuristics. Transfer to GS11 yields the average differences of 0.454 for max and 0.509 for heuristics. Note that the PhraseRel to GS11 transfer is the only case where max selection on average is better than heuristics.

In general, over all compositional datasets, we see---in contrast to the lexical evaluation---that the Max-based selection might be prone to overfitting (H\ref{hyp:overfitting}). However, the result difference is far beyond H\ref{hyp:10percent}, which might be due to the different nature of the tasks: similarity, disambiguation and relevance.

\section{Universal parameter selection for compositional datasets}
\label{sec:robust-param-comp-selecion}

Figure~\ref{fig:compositional-results} shows the performance of the models based on the combined selection over the KS14, GS11 and PhraseRel datasets. The combined score is calculated the following way:
%
\scriptsize
\begin{align*}
\operatorname{score}_\mathit{compositional}&(\mathit{model}, \mathit{operator}) =\\
&\frac{1}{3}%
\frac{\operatorname{score}_\mathit{KS14}(\mathit{model}, \mathit{operator})}%
{\max_m\operatorname{score}_\mathit{KS14}(m, \mathit{operator})}%
+%
\frac{1}{3}%
\frac{\operatorname{score}_\mathit{GS11}(\mathit{model}, \mathit{operator})}%
{\max_m\operatorname{score}_\mathit{GS11}(m, \mathit{operator})}%
+%
\frac{1}{3}%
\frac{\operatorname{score}_\mathit{PhraseRel}(\mathit{model, \mathit{operator}})}%
{\max_m\operatorname{score}_\mathit{PhraseRel}(m, \mathit{operator})}%
\end{align*}
\normalsize
The performance of selected models together with the selected parameters is shown on the Table~\ref{tab:compositional-max-selection} (Max selection) and Table~\ref{tab:compositional-heuristics-selection} (selection based on heuristics).

\input{figures/compositional-results}

\subsection{Max selection}
\label{sec:max-selection-compositional}

Models with many dimensions not always perform better than their low-dimensional counterparts. Particularly, only \texttt{head} and multiplication benefit from the high number of dimensions. Addition and Kronecker are closer to the upper bound with the dimensionality of few thousands.

\input{figures/compositional-ablation}

Regarding the hypotheses, there is support of H\ref{hyp:freq} for addition, multiplication and Kronecker, H\ref{hyp:cds} for multiplication and H\ref{hyp:neg} for Kronecker.

\subsection{Heuristics}
\label{sec:heuristics-compositional}

The linear model achieves the $R^2 = 0.769$. Table~\ref{tab:compositional-ablation} shows the partial $R^2$ values for the parameters. The most influential parameters are \texttt{neg}, \texttt{freq} and compositional operator.

\subsubsection{Neg}
\label{sec:neg-compositional}

\input{figures/compositional-neg}

For \texttt{head} and models with $D < 10000$ the \texttt{neg} should be set to 1, otherwise it should be 1.4 (Figure~\ref{fig:compositional-neg}).

For addition, 1 is the best choice of \texttt{neg}, but the performance of $k$ values follows H\ref{hyp:neg}.

Multiplication benefits from denser spaces. If the dimensionality is less than 10000, then \texttt{neg} should be set to 0.5, otherwise 0.7 is a good choice, confirming H\ref{hyp:neg}.

Kronecker benefits from the \texttt{neg} of 0.7 if $D < 10000$ and from 1 for the more dimensional cases, supporting H\ref{hyp:neg}. This is similar to multiplication, but Kronecker prefers less dense vectors.

\subsubsection{Freq}
\label{sec:freq-compositional}

$\log n$ is the frequency value of choice of all operators with an exception of multiplication, where the constant frequency is preferred (Figure~\ref{fig:compositional-freq}).

1 behaves good for low-dimensional vector spaces ($D \leq 5000$), giving support of H\ref{hyp:freq}.

\subsubsection{Context distribution smoothing}
\label{sec:cont-distr-smooth-compositional}

\input{figures/compositional-cds}

As Figure~\ref{fig:compositional-cds} shows, global context probability is the preferred choice of context probability in all cases, with an exception of Kronecker with $D > 3000$, where smoothed local probabilities are better ($\alpha = 0.75$), supporting H\ref{hyp:cds}.

\subsubsection{Similarity}
\label{sec:similarity-compositional}

Correlation is the dominant choice of the similarity measure (Figure~\ref{fig:compositional-similarity}). However, cosine is preferred in the case of \texttt{head}, with $D > 5000$, and inner product is the only choice for the composition with Kronecker with $D > 3000$.

There is no distinction between cosine and correlation for all compositional operators, which does not contradict H\ref{hyp:similarity}.

\subsubsection{Discr}
\label{sec:discr-compositional}

\input{figures/compositional-discr}

SPMI is the choice of \texttt{discr} that leads to the best average performance in most cases (Figure~\ref{fig:compositional-discr}). However the difference between SPMI and SCPMI is very small.

The exceptions are Multiplicative composition with $D \geq 10000$ and Kronecker with $D \leq 5000$ where SCPMI outperforms SPMI, as expected by H\ref{hyp:comp-pmi-cpmi}.

\subsection{Comparison with the single dataset beased selections}
\label{sec:comp-with-single-comp}

Manual selection based on a combination of the compositional datasets is more stable with regards to the chosen parameter values than the selection based on the highest values, even though manual selection does not always achieve the performance of Max selection, see Figure~\ref{fig:compositional-results}.

The average difference with the upper bound is 0.040 and 0.041 for Max and heuristics, respectively, when applied to KS14. For GS11, the difference is 0.045 (Max) and 0.127 (Heuristics). For PhraseRel, the difference is 0.055 (Max) and 0.084 (Heuristics).

The numbers are much lower than the transfer of spaces selected on the basis of one dataset (Section~\ref{sec:select-model-transf-comp}). The average normalised difference is within the 10\% limit (H\ref{hyp:10percent}), with an exception of heuristics on GS11. This is an evidence, that there might be one universal model that fits various tasks H\ref{hyp:universal}. The fact that the average normalised difference is smaller for Max-based selection is against H\ref{hyp:overfitting}, a combination of datasets that covers several phenomena (in our case, similarity, disambiguation and relatedness) might be more effective than manual heuristic-based selection.

The model selection procedures improve from combination of datasets. One needs to keep in mind that in this case we test model performance on the same dataset as we do parameter selection.

\section{Conclusion}
\label{sec:conclusion-comp}

Phrasal experiments support most of the hypotheses stated in
Sections~\ref{sec:hypotheses}, \ref{sec:elab-hypoth-lexical} and
\ref{sec:elab-hypoth-comp}.

The confirmation of hypotheses on optimal parameter dependence on dimensionality (in particular H\ref{hyp:freq} and H\ref{hyp:neg}, that are supported by all datasets) confirms H\ref{hyp:dimen}. It worth noting, that even though an optimal choice of \texttt{cds} does not depend on dimensionality on KS14 and GS11, in the combined case the dependence holds.

Models that are selected on the experiments on a single dataset are prone to overfitting. Neither manual selection of parameters prevents it, the average normalised difference is above 10\% on model transfer. This confirms H\ref{hyp:overfitting} and rejects H\ref{hyp:10percent}.

Model selection based on combination of datasets performs much better on each datasets (contrary to a single-dataset selected models). Both selection methods are within 10\%, supporting H\ref{hyp:10percent}.

Max selection models outperform heuristic selection models, suggesting that there is no overfitting in this case and H\ref{hyp:overfitting} is not valid. In this case, the dataset combination covered three phenomena (similarity, disambiguation and relevance) and the precaution of overfitting by heuristics might be redundant.

This also suggests, that there is a unique parameter choice that is universally applicable to compositional tasks H\ref{hyp:universal}.

\chapter[Universal models]{Universal models for both lexical and compositional tasks}
\label{sec:universal-param-selection}

\section{Operator-dependent universal models}
\label{sec:model-selection}

\subsection{Max selection}
\label{sec:max-selection-universal}

Table~\ref{tab:universal-max-selection} shows the performance of the models selected by a combined score of the lexical and compositional datasets. The combined score is computed as:
%
\scriptsize
\begin{align*}
\operatorname{score}_\mathit{universal}&(\mathit{model}, \mathit{operator}) =\\%
& \frac{1}{2}\left(
\frac{1}{2}%
\frac{\operatorname{score}_\mathit{SimLex-999}(\mathit{model})}%
{\max_m\operatorname{score}_\mathit{SimLex-999}(m)}%
+%
\frac{1}{2}%
\frac{\operatorname{score}_\mathit{MEN}(\mathit{model})}%
{\max_m\operatorname{score}_\mathit{MEN}(m)}%
\right) +
\\
&\frac{1}{2}\left(
\frac{1}{3}%
\frac{\operatorname{score}_\mathit{KS14}(\mathit{model}, \mathit{operator})}%
{\max_m\operatorname{score}_\mathit{KS14}(m, \mathit{operator})}%
+%
\frac{1}{3}%
\frac{\operatorname{score}_\mathit{GS11}(\mathit{model}, \mathit{operator})}%
{\max_m\operatorname{score}_\mathit{GS11}(m, \mathit{operator})}%
+%
\frac{1}{3}%
\frac{\operatorname{score}_\mathit{PhraseRel}(\mathit{model, \mathit{operator}})}%
{\max_m\operatorname{score}_\mathit{PhraseRel}(m, \mathit{operator})}%
\right)
\end{align*}
\normalsize

Parameter selection is much more stable than on all previous max-based selections. $\log n$ is the dominant \texttt{freq} choice, cosine is the measure of choice for multiplication and Kronecker (if available). Correlation is the best similarity measure for additive composition. The optimal choice of a similarity measure does not depend on dimensionality, this observation does not support H\ref{hyp:similarity}.

Interestingly, when shifting is applied, then dense spaces perform better: 1 and 0.7 are the optimal \texttt{neg} values. Multiplication shows a clear patter in support of H\ref{hyp:neg}.

\todo[noline]{This is one of the major findings.}
Compositional operator preference depends on the focus of a model.
Addition with many dimensions gives the best results on lexical tasks: 0.384 on SimLex-999 and 0.761 on MEN. Kronecker, on the other side, gives the highest values for compositional datasets supporting H\ref{hyp:order}: 0.798 on KS14, 0.514 on GS11 and 0.964 on PhraseRel. Multiplication, however, is a good compromise between the two. It gives the highest ``combined'' score of 0.945.

\subsection{Heuristics}
\label{sec:heuristics-universal}

\input{figures/universal-ablation}

Performance of the models selected manually is shown on Table~\ref{tab:universal-heuristics-selection}. Again, there is a lot consistency between parameters. The linear model achieves $R^2 = 0.828$. The most influencing parameters are \texttt{freq}, \texttt{neg} and a similarity measure, refer to Table~\ref{tab:universal-ablation} for more details.

Heuristics for addition choose models that score the highest on lexical tasks: 0.384 on SimLex-999 and 0.764 on MEN (Table~\ref{tab:universal-heuristics-selection}). Moreover, with more than 20000 dimensions there is no difference between the selection procedures (Max or heuristics) of the additive and Kronecker-based models.

Kronecker is strong in compositional tasks scoring 0.795 on KS14, 0.516 on GS11 and 0.929 on PhraseRel, which is inline with H\ref{hyp:order} (Table~\ref{tab:universal-heuristics-selection}).

Multiplication and Kronecker support H\ref{hyp:neg}: the optimal shifting value $k$ depends on the dimensionality. Addition and Kronecker are consistent with H\ref{hyp:cds}, low-dimensional spaces benefit from global context probabilities, while high-dimensional spaces benefit from smoothed context probabilities with $\alpha=0.75$.

Multiplication, again, is a compromise between the two: it gives the highest combined score of 0.941. The highest Kronecker's combined score is 0.913, while addition's highest score is only 0.843.

Regarding the hypotheses, we clearly see that there is a little difference between 1 and $\log n$ frequencies for low-dimensional spaces, but $\log n$ it best choice for high-dimensional spaces which is consistent with H\ref{hyp:freq}.

Shifting performs also in accordance to H\ref{hyp:neg}: for low-dimensional spaces $k=0.7$ or even $k=0.5$ leads to the highest result, while for high-dimensional spaces $k=1$ or $k=1.4$ are optimal.

We also see that there is no difference between cosine and correlation similarity measures giving a weak support of H\ref{hyp:similarity}.

Addition and Kronecker work best with global context probabilities on low-dimensional spaces, but benefit from local probabilities ($\alpha=0.75$) for high-dimensional spaces, supporting H\ref{hyp:cds}. Multiplication, however, does not follow H\ref{hyp:cds} as $\alpha=0.75$ leads to weak performance for all dimensions.

There is no support of H\ref{hyp:comp-pmi-cpmi}: for all operators, there is little difference between SPMI and SCPMI.

\subsection{Comparison of the selection methods}
\label{sec:comparison-universal}

On lexical tasks, there is little difference between the model selection methods especially for spaces with more than 30000 dimensions, as Figures~\ref{fig:universal-results-simlex} and \ref{fig:universal-results-men} show.

The average relative differences for Max selection are 0.034 (SimLex-999), 0.010 (MEN), 0.033 (KS14), 0.109 (GS11) and 0.061 (PhraseRel). For manual heuristics, the differences are 0.047 (SimLex-999), 0.009 (MEN), 0.034 (KS14), 0.114 (GS11) and 0.065 (PhraseRel). The numbers between different selection methods are close, with the exceptions of SimLex-999 (where Max selection is 0.013 points lower), and GS11, where Max is lower by 0.05 points.

The high relative difference on GS11 is due to a poor performance of addition and \texttt{head}. The average normalised difference for addition is 0.219 for Max selection and 0.224 for heuristics. For \texttt{head} the differences are 0.105 and 0.141 respectively. The differences for multiplication and Kronecker are less than 0.07, which is according to H\ref{hyp:10percent}.

Contrary to H\ref{hyp:overfitting}, Max selection does not overfit, probably due to a broad selection of evaluation datasets.

\todo[noline]{One of the major findings.}
When the models that are selected on lexical tasks are applied in a compositional setting, they perform worse than the models selected based on the universal score. This suggests that a model that is good on lexical tasks will not necessarily perform well on a compositional task, supporting H\ref{hyp:lextocomp}.

In addition, the difference between the good lexical models and the upper bound increases as dimensionality increases. This is the case for multiplication, the most notable difference is observed on KS14 (Figure~\ref{fig:universal-results-ks14}).

It worth noting that on compositional tasks dimensionality does not contribute as much as on lexical tasks, with an exception of addition on the GS11 dataset, where performance decreases as dimensionality increases.

\section{An operator-independent universal model}
\label{sec:single}

In the previous section we have seen that even though parameter selection varies between operators, there are parameter choices that are shared. Given this and the fact that the difference between some of the choices is marginal, we try to look for a truly universal parameter combination.

The experiment scores are aggregated as:
\scriptsize
\begin{align*}
\operatorname{score}_\mathit{universal}&(\mathit{model}) =\\%
& \frac{1}{2}\left(
\frac{1}{2}%
\frac{\operatorname{score}_\mathit{SimLex-999}(\mathit{model})}%
{\max_m\operatorname{score}_\mathit{SimLex-999}(m)}%
+%
\frac{1}{2}%
\frac{\operatorname{score}_\mathit{MEN}(\mathit{model})}%
{\max_m\operatorname{score}_\mathit{MEN}(m)}%
\right)+
\\
&\frac{1}{2}\Bigg(
\frac{1}{6}%
\frac{\operatorname{score}_\mathit{KS14}(\mathit{model}, \mathit{add})}%
{\max_m\operatorname{score}_\mathit{KS14}(m, \mathit{add})}%
+%
\frac{1}{6}%
\frac{\operatorname{score}_\mathit{GS11}(\mathit{model}, \mathit{add})}%
{\max_m\operatorname{score}_\mathit{GS11}(m, \mathit{add})}%
+%
\frac{1}{6}%
\frac{\operatorname{score}_\mathit{PhraseRel}(\mathit{model, \mathit{add}})}%
{\max_m\operatorname{score}_\mathit{PhraseRel}(m, \mathit{add})}
+
\\
&\phantom{\frac{1}{2}\Bigg(}
\frac{1}{6}%
\frac{\operatorname{score}_\mathit{KS14}(\mathit{model}, \mathit{mult})}%
{\max_m\operatorname{score}_\mathit{KS14}(m, \mathit{mult})}%
+%
\frac{1}{6}%
\frac{\operatorname{score}_\mathit{GS11}(\mathit{model}, \mathit{mult})}%
{\max_m\operatorname{score}_\mathit{GS11}(m, \mathit{mult})}%
+%
\frac{1}{6}%
\frac{\operatorname{score}_\mathit{PhraseRel}(\mathit{model, \mathit{mult}})}%
{\max_m\operatorname{score}_\mathit{PhraseRel}(m, \mathit{mult})}
\Bigg)
\end{align*}
\normalsize

\subsection{Max selection}
\label{sec:max-selection-single}

Table~\ref{tab:single-max-selection} shows the combined scores for all datasets abstracting over a compositional operator.

The parameter selection shows a clear pattern. Low-dimensional spaces perform best with 1 as the frequency choice, while high dimensional models perform better with $\log n$ confirming H\ref{hyp:freq}. Cosine is a better suited similarity measure for models with few dimensions, correlation with many, which is inline with H\ref{hyp:similarity}. Finally, global context probabilities are the best in a low-dimensional case, while local context probabilities perform best with many dimensions supporting H\ref{hyp:cds}.

\subsection{Heuristics}
\label{sec:heuristics-single}

\input{figures/single-ablation}
The linear model gives $R^2 = 0.898$. The most influential parameters are \texttt{freq}, similarity measure and \texttt{neg}, refer to Table~\ref{tab:single-ablation}.

Heuristics in general repeat the parameter choice of Max selection, but the switch between parameter values happens at more dimensions (at 20000, not at 5000) refer to Table~\ref{tab:single-heuristics-selection} for the results and Figure~\ref{fig:single-params} for the parameter behaviour.

The average normalised differences with the upper bound for Max selection are 0.049 (SimLex-999), 0.032 (MEN), 0.063 (KS14), 0.106 (GS11) and 0.116 (PhraseRel). The differences for heuristics are in general higher: 0.062 (SimLex-999), 0.045 (MEN), 0.076 (KS14), 0.090 (GS11) and 0.139 (PhraseRel).

Max selection is above the 10\% margin of H\ref{hyp:10percent} on GS11 and PraseRel, while heuristics are above the margin only on PhraseRel.

% \subsubsection{Tweaked IR evaluation}
% \label{sec:tweak-ir-eval}

% \todo[inline]{Discuss \cite{Milajevs:2015:IMN:2808194.2809448} and link to \ref{sec:phraserel}}

% \section{PhraseRel: relevance of sentences}
% \label{sec:sentential-relevance}


\section{Experiments with tensor-based compositional operators}
\label{sec:frob-comp-oper}

Sections~\ref{sec:model-selection} and \ref{sec:single} identified models that perform well on a range of tasks. The majority of them are withing the 10\% margin set by H\ref{hyp:10percent}.

\input{figures/frobenius-results}

We apply these models with tensor-based operators on phrasal datasets (KS14, GS11 and PhraseRel). Table~\ref{tab:frobenius-results} shows the best results we obtained for each operator, Tables~\ref{tab:frobenius-ks14-results}, \ref{tab:frobenius-gs11-results} and \ref{tab:frobenius-phraserel-results} show all the results together with the model parameters and Figure~\ref{fig:frobenius-results} depicts the data.

In general, the best results are achieved with 3000 dimensional models (with an exception on GS11 where 1000 dimensional models perform better in 4 out of 6 cases, and copy-subject on KS14). Also, performance increases as dimensionality increases.

Max selection based on Kronecker leads to the highest results, with an exception of Frobenius multiplication and copy-subject on KS14, where Max-add leads to the highest results. On PhraseRel, copy-subject performs best with operator-independently selected space.

Relational is the best compositional operator---which is other that addition, multiplication or Kronecker---on KS14 (0.768) and PhraseRel (0.893). Copy-subject is the best on GS11 (0.402). Frobenius-outer gives the highest result on PhraseRel together with relational.

On GS11 and PhraseRel, newly tested operators outperform addition, whose scores are 0.338 and 0.893 respectively.

While there is difference between selection methods, there are no clear outliers and the models show similar behaviour.

\section{Putting results into perspective}
\label{sec:comp-with-other}

This section discussed the results of the experiments in the context of other work.

The earliest of the relevant studies is the work of \newcite{milajevs-EtAl:2014:EMNLP2014}. They evaluate two count-based vector spaces and a space based on the original word2vec vectors obtained from the Google News corpus \cite{mikolov2013distributed} and experiment with the same compositional operators as this work. Their count-based models are the ones that are considered to be efficient in compositional task and are used in the studies that introduced the evaluation datasets---KS14 \cite{kartsadrqpl2014} and GS11 \cite{Grefenstette:2011:ESC:2145432.2145580}---and therefore can be seen as replication of the experiments in those papers. They conclude that on small-scale tasks (KS14 and GS11) count-based models are competitive with the neural word vectors.

They achieve the best result of 0.732 with additive composition on KS14 with an SVD-reduced vector space. Their best tensor-based result is 0.655 achieved with word2vec and copy object. Our models (Table~\ref{tab:frobenius-results}), with an exception of copy object, improve over their best score. Even being lower, our copy-object (0.628) is close to the score reported in \cite{milajevs-EtAl:2014:EMNLP2014}.

On the GS11 dataset, our spaces improve over the corresponding operators on all but two compositional methods (exceptions are copy object and Frobenius mult). Only multiplication and Kronecker improve over the best reported score of 0.456 in \newcite{milajevs-EtAl:2014:EMNLP2014}. Kronecker yields the highest score of 0.516.

\newcite{kim2015neural} adopted the evaluation procedure of \newcite{milajevs-EtAl:2014:EMNLP2014} to test an extended word2vec model that is tuned for multiplicative interaction of the vectors, not additive. The improve on most of the composition operators on the KS14 and GS11 datasets.

They achieve the best result of 0.770 with addition on KS14. 3 our our models (addition, multiplication and Kronecker) outperform that. Also, our results are better than the results reported there ``operator-wise''.

On G11, their best score is 0.387, which is lower than the results that we get with multiplication, Kronecker, relational and copy subject. However, we get lower results with Copy object and Frobenius outer.

\newcite{hashimoto-tsuruoka:2015:CVSC}

% \newcite{zanzotto-pennacchiotti-pazienza:2006:COLACL}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
