\chapter{Introduction}
\label{ch:introduction}


Computers require specially designed programming languages to be controlled, despite the fact that they play a crucial role in our lives. Ideally, it would be perfect if the interaction with computers was not different from the interaction between humans. Computational linguistics is one of the fields that addresses this problem.

In order to be controlled by people in a casual manner, or be able to assist people in life, computers need to understand human language. However, different tasks require various levels of language understanding. For instance, even if one does not recognize or know the language of a piece of text in Figure~\ref{fig:lv}, one can tell how many words there are, and that there is only one sentence. One can even argue that this is a piece of poetry basing the argument on the shape of the text.

The conclusions above require neither the complete understanding of the language nor the meaning of the text. The knowledge that texts---at least in some languages---consist of words separated by a space and how poems are written is enough. Moreover, knowing the letter distribution across all human languages or having a list of words in them, one would conclude that the text is in Latvian. This information can be provided without knowing what the text is about and are currently successfully done by computers.

\input{poem.tex}

On the other hand, a task that asks for a list of associations, an essay or a painting inspired by a piece of text demands a much better understanding of the text that requires a deeper knowledge of the language and greater familiarity with the culture. Luckily, nowadays these kinds of tasks are not expected to be completed by computers in day-to-day life because people enjoy doing these things themselves.

However, it is reasonable to ask a computer the following questions regarding the text:
\begin{inparaenum}[a)]
\item What is the text of Figure~\ref{fig:lv} about?
\item What is the relationship between the texts in Figure~\ref{fig:lv} and
  Figure~\ref{fig:ru}?
% the *meanings are identical*
\item Is the content similar or identical?
\item Where did the meeting take place?
\item What poems are similar to this?
\end{inparaenum}

Text summarisation, machine translation, information extraction and information retrieval are branches of computational linguistics that provide methods for answering these questions. The questions above have a general property: all of them are about the certain aspect of the text meaning. Semantics is an area that studies meaning representation and thus, is necessary to solve the tasks.

While it is not completely known how meaning is represented in the human mind, it is argued that similarity between two events or objects is based on the way humans represent them \cite{WCS:WCS1282}. Similarity judgements are easy to collect. Many similarity datasets exist that serve as proxies for the evaluation of computational models of meaning.

The distributional hypothesis of \citet{harris1954distributional}---that semantically similar words tend to appear in similar contexts---stands behind the distributional models of meaning. In Figure~\ref{fig:en}, the side-street occurs with the words as though, noise, hustle and smells. Such a company of words starkly contrasts with the words used to describe the woman: she is young, attractive and active.

Moreover, the descriptive terms of the side-street bring images of other similar things that are though and smell. At the same time, the descriptive terms of the woman fire in the mind attractive and active associations making the difference between the street and the woman even stronger!

Distributional models of meaning are based on the co-occurrence statistics of words in a large collection of texts \cite{Turney:2010:FMV:1861751.1861756,mikolov2013linguistic,mikolov2013distributed,mikolov2013efficient}. The models are well studied and their estimates of the similarity between word pairs are very close to the human judgements \cite{TACL570,baroni-dinu-kruszewski:2014:P14-1,Halawi:2012:LLW:2339530.2339751}.

% At the same time, developments in compositional distributional semantics \cite{mitchell2010composition,maillard-clark-grefenstette:2014:TTNLS,Grefenstette:2011:ESC:2145432.2145580,Grefenstette:2011:ETV:2140490.2140497,kartsadrqpl2014,fried-polajnar-clark:2015:ACL-IJCNLP} showed that Frege's principle of compositionality \cite{Janssen2001} is useful in obtaining representations of phrases and sentences.
% % * <sdyck@ualberta.ca> 2016-11-03T00:28:29.470Z:
% %
% % > word2vec
% %
% % I would briefly explain what this is, otherwise the second point in this paragraph about Frege's principle doesn't have much context. 
% %
% % ^.

% % The creativity of natural languages---the fact that humans are able to produce
% % and understand sentences they have never come across---complicates modelling of
% % text meaning. Even if we had a way to map each word to its meaning, it is
% % impractical to apply the same procedure to sentences because as we process a
% % piece of text, most of the sentences in it will be seen for the fist time.
% % Therefore, we need to be able to build the meaning of a sentence from its
% % constituent parts, rather than a sentence in its entirety.

% % Syntax is the study of the structure of a sentence. Grammar defines the rules
% % that describe what a sentence that belongs to a language should look like. For
% % example, in an English sentence, a subject is written before a verb and an
% % object is after. Having the constituent meaning representations, the meaning of
% % a sentence is built by following its syntactic structure.

% % To be able to deal with the meaning of a text in a natural language, one needs to have meaning representation of constituents, the syntactic structure and a compositional procedure that outputs the meaning representation.

% % Even though the new generation of meaning representation models is shown to be superior in compositional tasks \cite{milajevs-EtAl:2014:EMNLP2014}, it has been criticised---most notably by \newcite{TACL570}. However, it is not yet known whether the critique of word2vec also applies to the compositional setting.
% % % * <sdyck@ualberta.ca> 2016-11-03T00:31:07.929Z:
% % %
% % % > compositional 
% % %
% % % should this be lexical?
% % %
% % % ^.

% This work adopts the recommendations of \newcite{TACL570} for model parameter tuning and performs a large-scale model selection study on lexical and compositional tasks.
% % * <sdyck@ualberta.ca> 2016-11-03T00:37:45.835Z:
% %
% % > This work adopts the recommendations of \newcite{TACL570} for model parameter tuning and performs a large-scale model selection study on lexical and compositional tasks.
% %
% % ^.

% This work shows that after a careful selection of  vector space model
% parameters, the selected models are comparable with the current state-of-the-art results and on some datasets, outperform them.
% % * <sdyck@ualberta.ca> 2016-11-03T00:32:14.807Z:
% %
% % > The experiments show that after a careful selection of  vector space model parameters, the selected models are competitive with the current state-of-the-art results and on some datasets outperform it.
% %
% % This sentence could use a bit of clarification. What kind of results are you talking about? Maybe use the word model(s) rather than results.
% %
% % ^.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% TeX-engine: xetex
%%% End:
